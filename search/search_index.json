{"config":{"lang":["en"],"separator":"[\\s\\-,:!=\\[\\]()\"`/]+|\\.(?!\\d)|&[lg]t;|(?!\\b)(?=[A-Z][a-z])","pipeline":["stopWordFilter"],"fields":{"title":{"boost":1000.0},"text":{"boost":1.0},"tags":{"boost":1000000.0}}},"docs":[{"location":"","title":"NLP-Driven Incident Triage","text":"<p>Educational cybersecurity incident triage platform demonstrating intelligent classification through Natural Language Processing, LLM enhancement, and uncertainty-aware predictions.</p> <ul> <li> Quick Start</li> </ul> <p>Get up and running in minutes with our streamlined setup guide</p> <p> Getting Started</p> <ul> <li> CLI Tool</li> </ul> <p>Powerful command-line interface for incident classification</p> <p> CLI Usage</p> <ul> <li> Web Interface</li> </ul> <p>Interactive Streamlit UI with visual analytics and bulk processing</p> <p> UI Guide</p> <ul> <li> Dataset Generation</li> </ul> <p>Create synthetic SOC datasets with LLM enhancement</p> <p> Data &amp; Generator</p>"},{"location":"#overview","title":"Overview","text":"<p>An educational/research platform demonstrating intelligent cybersecurity incident triage through Natural Language Processing. This project showcases how analyst-style narratives can be converted into structured incident categories using a transparent, reproducible ML workflow.</p> <p>Educational Project - Not Production IR Tooling</p> <p>This project is designed for education, research, and portfolio demonstration.  It is not a drop-in replacement for enterprise incident response systems and should not be deployed unsupervised in a live SOC environment.</p>"},{"location":"#key-features","title":"\u2728 Key Features","text":"<ul> <li> LLM-Enhanced Generation</li> </ul> <p>Local llama.cpp models for privacy-first intelligent dataset creation with sanitization and caching</p> <ul> <li> Uncertainty-Aware Classification</li> </ul> <p>TF-IDF + Logistic Regression with configurable thresholds and intelligent fallback handling</p> <ul> <li> Second-Opinion Engine</li> </ul> <p>LLM assistance for uncertain cases with JSON guardrails and hallucination prevention</p> <ul> <li> Interactive Analytics</li> </ul> <p>Streamlit UI with real-time classification, bulk analysis, and visual threat intelligence</p> <ul> <li> Production Monitoring</li> </ul> <p>Real-time progress tracking, ETA calculation, and resource efficiency metrics</p> <ul> <li> Research-Grade Dataset</li> </ul> <p>100k synthetic incidents with MITRE ATT&amp;CK enrichment and realistic noise</p>"},{"location":"#architecture-overview","title":"\ud83c\udfd7\ufe0f Architecture Overview","text":"<pre><code>graph TB\n    A[Data Generation] --&gt;|LLM Rewriter| B[Synthetic Dataset]\n    B --&gt; C[Preprocessing Pipeline]\n    C --&gt; D[TF-IDF Vectorization]\n    D --&gt; E{Baseline Classifier}\n    E --&gt;|High Confidence| F[Direct Classification]\n    E --&gt;|Low Confidence| G[LLM Second Opinion]\n    G --&gt; H[Final Decision]\n    F --&gt; H\n    H --&gt; I[CLI Output]\n    H --&gt; J[Streamlit UI]\n    H --&gt; K[JSON Export]\n\n    style E fill:#9c27b0,stroke:#7b1fa2,color:#fff\n    style G fill:#ff9800,stroke:#f57c00,color:#fff\n    style H fill:#4caf50,stroke:#388e3c,color:#fff</code></pre>"},{"location":"#use-cases","title":"\ud83c\udfaf Use Cases","text":"EducationResearchPortfolio <ul> <li>Learn NLP techniques for cybersecurity</li> <li>Understand uncertainty-aware classification</li> <li>Explore MITRE ATT&amp;CK framework integration</li> <li>Study SOC automation concepts</li> </ul> <ul> <li>Prototype triage automation ideas</li> <li>Experiment with LLM-enhanced generation</li> <li>Test classification algorithms</li> <li>Develop synthetic security datasets</li> </ul> <ul> <li>Demonstrate ML engineering skills</li> <li>Showcase end-to-end project development</li> <li>Highlight production-grade tooling</li> <li>Present interactive visualizations</li> </ul>"},{"location":"#quick-examples","title":"\ud83d\ude80 Quick Examples","text":""},{"location":"#cli-classification","title":"CLI Classification","text":"<pre><code># Basic incident analysis\nnlp-triage \"User reported suspicious email with attachment\"\n\n# JSON output for scripting\nnlp-triage --json \"Multiple failed login attempts detected\"\n\n# LLM-assisted bulk processing\nnlp-triage --llm-second-opinion \\\n  --input-file incidents.txt \\\n  --output-file results.jsonl\n</code></pre>"},{"location":"#dataset-generation","title":"Dataset Generation","text":"<pre><code># Quick generation (1000 incidents)\npython generator/generate_cyber_incidents.py --n-events 1000\n\n# Production with monitoring\n./generator/launch_generator.sh 50000 my_dataset\n./generator/monitor_generation.sh my_dataset --watch\n</code></pre>"},{"location":"#streamlit-ui","title":"Streamlit UI","text":"<pre><code># Launch interactive interface\nstreamlit run ui_premium.py\n</code></pre>"},{"location":"#whats-inside","title":"\ud83d\udcca What's Inside","text":"Component Description Dataset 100k synthetic SOC incidents with multi-perspective narratives Models TF-IDF vectorizer + Logistic Regression baseline CLI Rich-formatted command-line interface with uncertainty logic UI Streamlit web application with visual analytics Notebooks 9 Jupyter notebooks covering full ML pipeline Generator LLM-enhanced synthetic data creation with monitoring Tests Comprehensive pytest suite with CI/CD Docs MkDocs Material documentation site"},{"location":"#learning-path","title":"\ud83c\udf93 Learning Path","text":"<p>New to the project? Follow this recommended learning path:</p> <ol> <li> Getting Started - Set up environment and run first predictions</li> <li> CLI Usage - Master the command-line interface</li> <li> Dataset Generation - Understand the synthetic data</li> <li> Modeling &amp; Evaluation - Deep dive into the ML pipeline</li> <li> Notebooks Overview - Explore interactive analysis</li> <li> Development Guide - Contribute to the project</li> </ol>"},{"location":"#technical-highlights","title":"\ud83d\udd2c Technical Highlights","text":""},{"location":"#shared-preprocessing-pipeline","title":"Shared Preprocessing Pipeline","text":"<ul> <li>Consistent text cleaning across training and inference</li> <li>Unicode normalization and punctuation cleanup</li> <li>TF-IDF feature extraction with 5k feature limit</li> </ul>"},{"location":"#uncertainty-aware-predictions","title":"Uncertainty-Aware Predictions","text":"<ul> <li>Configurable confidence thresholds</li> <li>Intelligent <code>uncertain</code> fallback for ambiguous cases</li> <li>Scenario-driven behavior matching SOC reality</li> </ul>"},{"location":"#llm-integration","title":"LLM Integration","text":"<ul> <li>Privacy-first local inference (llama.cpp)</li> <li>JSON parsing guardrails</li> <li>SOC keyword validation</li> <li>Deterministic rationale generation</li> </ul>"},{"location":"#production-grade-tooling","title":"Production-Grade Tooling","text":"<ul> <li>Checkpoint-based resumable generation</li> <li>Real-time progress monitoring</li> <li>Resource efficiency tracking</li> <li>Comprehensive error handling</li> </ul>"},{"location":"#documentation-structure","title":"\ud83d\udcda Documentation Structure","text":"<ul> <li> User Guide</li> </ul> <p>Learn how to use the tools and interfaces</p> <p> CLI Usage  Streamlit UI  Dataset Generation  Configuration</p> <ul> <li> Technical Deep Dive</li> </ul> <p>Understand the architecture and implementation</p> <p> Architecture  Model Information  Modeling &amp; Evaluation  LLM Integration</p> <ul> <li> Development</li> </ul> <p>Contribute to the project</p> <p> Development Guide  Testing  API Reference  Contributing</p> <ul> <li> Reference</li> </ul> <p>Additional information and resources</p> <p> Limitations &amp; Safety  MITRE Attribution  FAQ  Glossary</p>"},{"location":"#project-goals","title":"\ud83c\udf1f Project Goals","text":"<p>This project aims to demonstrate:</p> <p>\u2705 End-to-end ML pipeline from data generation to deployment \u2705 Uncertainty-aware classification for real-world ambiguity \u2705 Privacy-first LLM integration for enhanced intelligence \u2705 Production-grade monitoring and observability \u2705 Interactive visualizations and analytics \u2705 Comprehensive documentation and testing</p>"},{"location":"#contributing","title":"\ud83e\udd1d Contributing","text":"<p>Contributions are welcome! Whether it's:</p> <ul> <li>\ud83d\udc1b Bug reports</li> <li>\ud83d\udca1 Feature requests</li> <li>\ud83d\udcd6 Documentation improvements</li> <li>\ud83d\udd27 Code contributions</li> </ul> <p>See our Contributing Guide to get started.</p>"},{"location":"#license","title":"\ud83d\udcc4 License","text":"<p>This project is licensed under the Apache License 2.0. See LICENSE for details.</p>"},{"location":"#links","title":"\ud83d\udd17 Links","text":"<ul> <li> GitHub Repository</li> <li> Full Documentation</li> <li> Issue Tracker</li> <li> Discussions</li> </ul>"},{"location":"api-reference/","title":"API Reference","text":"<p>Coming Soon</p> <p>Comprehensive API documentation is being developed.</p>"},{"location":"api-reference/#core-modules","title":"Core Modules","text":""},{"location":"api-reference/#triagepreprocess","title":"<code>triage.preprocess</code>","text":"<pre><code>from triage.preprocess import clean_description\n\nclean_text = clean_description(\"URGENT!!! Login FAILED!!!\")\n# Returns: \"urgent login failed\"\n</code></pre>"},{"location":"api-reference/#triagemodel","title":"<code>triage.model</code>","text":"<pre><code>from triage.model import load_vectorizer_and_model, predict_event_type\n\nvectorizer, classifier = load_vectorizer_and_model()\nlabel, probabilities = predict_event_type(\"Suspicious payroll login email\")\n</code></pre>"},{"location":"api-reference/#triagecli","title":"<code>triage.cli</code>","text":"<p>See CLI Usage for command-line interface documentation.</p>"},{"location":"api-reference/#function-reference","title":"Function Reference","text":""},{"location":"api-reference/#text-processing","title":"Text Processing","text":""},{"location":"api-reference/#clean_descriptiontext-str-str","title":"<code>clean_description(text: str) -&gt; str</code>","text":"<p>Cleans and normalizes incident text.</p> <p>Parameters:</p> <ul> <li><code>text</code> (str): Raw incident description</li> </ul> <p>Returns:</p> <ul> <li>str: Cleaned text (lowercase, normalized)</li> </ul>"},{"location":"api-reference/#model-loading","title":"Model Loading","text":""},{"location":"api-reference/#load_vectorizer_and_model-tuplevectorizer-classifier","title":"<code>load_vectorizer_and_model() -&gt; Tuple[Vectorizer, Classifier]</code>","text":"<p>Loads the saved TF\u2013IDF vectorizer and trained classifier used by the CLI.</p> <p>Returns:</p> <ul> <li>Tuple: <code>(vectorizer, classifier)</code> objects ready for inference</li> </ul>"},{"location":"api-reference/#inference","title":"Inference","text":""},{"location":"api-reference/#predict_event_typetext-str-top_k-int-5-tuplestr-optionaldictstr-float","title":"<code>predict_event_type(text: str, top_k: int = 5) -&gt; Tuple[str, Optional[Dict[str, float]]]</code>","text":"<p>Predicts the most likely incident label and (optionally) a top-k probability breakdown.</p> <p>Parameters:</p> <ul> <li><code>text</code> (str): Incident description</li> <li><code>top_k</code> (int): Maximum classes to include in the probability dict</li> </ul> <p>Returns:</p> <ul> <li>Tuple: <code>(label, probabilities)</code> where <code>label</code> is a string and <code>probabilities</code> is an optional dict of class \u2192 probability</li> </ul>"},{"location":"api-reference/#data-structures","title":"Data Structures","text":""},{"location":"api-reference/#prediction-result","title":"Prediction Result","text":"<p>Programmatic API returns a tuple. For a structured payload, use the CLI with <code>--json</code>.</p>"},{"location":"api-reference/#cli-integration","title":"CLI Integration","text":"<p>For programmatic usage, use JSON mode:</p> <pre><code>import subprocess\nimport json\n\nresult = subprocess.run(\n    [\"nlp-triage\", \"--json\", \"incident text\"],\n    capture_output=True,\n    text=True\n)\n\nprediction = json.loads(result.stdout)\n</code></pre> <p>For usage examples, see Notebooks Overview.</p>"},{"location":"architecture/","title":"System Architecture","text":""},{"location":"architecture/#overview","title":"Overview","text":"<p>The NLP-Driven Incident Triage system consists of multiple interconnected components that work together to provide intelligent incident classification.</p>"},{"location":"architecture/#component-diagram","title":"Component Diagram","text":"<pre><code>graph TB\n    subgraph \"Data Layer\"\n        A[Synthetic Generator] --&gt;|LLM Enhancement| B[Dataset CSV]\n        B --&gt; C[Checkpoint System]\n    end\n\n    subgraph \"Processing Layer\"\n        D[Preprocessing] --&gt; E[TF-IDF Vectorization]\n        E --&gt; F[Logistic Regression]\n    end\n\n    subgraph \"Intelligence Layer\"\n        G[Baseline Classifier] --&gt; H{Confidence Check}\n        H --&gt;|High| I[Direct Classification]\n        H --&gt;|Low| J[LLM Second Opinion]\n        J --&gt; K[Final Decision]\n        I --&gt; K\n    end\n\n    subgraph \"Interface Layer\"\n        L[CLI Tool]\n        M[Streamlit UI]\n        N[JSON API]\n    end\n\n    B --&gt; D\n    F --&gt; G\n    K --&gt; L\n    K --&gt; M\n    K --&gt; N</code></pre>"},{"location":"architecture/#components","title":"Components","text":""},{"location":"architecture/#data-generation","title":"Data Generation","text":"<ul> <li>Generator: Creates synthetic incidents with MITRE enrichment</li> <li>LLM Rewriter: Enhances narratives using llama.cpp</li> <li>Checkpoint System: Enables resumable generation</li> </ul>"},{"location":"architecture/#processing-pipeline","title":"Processing Pipeline","text":"<ul> <li>Text Cleaning: Unicode normalization, lowercase, punctuation</li> <li>TF-IDF: Bag-of-words with bigrams (~5k features)</li> <li>Classifier: Logistic Regression with class balancing</li> </ul>"},{"location":"architecture/#intelligence-layer","title":"Intelligence Layer","text":"<ul> <li>Uncertainty Detection: Configurable confidence thresholds</li> <li>LLM Integration: Local llama.cpp for second opinions</li> <li>Guardrails: JSON parsing, keyword validation, label normalization</li> </ul>"},{"location":"architecture/#interfaces","title":"Interfaces","text":"<ul> <li>CLI: Rich-formatted terminal interface</li> <li>Streamlit UI: Interactive web dashboard</li> <li>JSON Output: Scriptable batch processing</li> </ul>"},{"location":"architecture/#data-flow","title":"Data Flow","text":"<ol> <li>Generation: Synthetic incidents created with optional LLM enhancement</li> <li>Storage: CSV format with checkpointing for large datasets</li> <li>Preprocessing: Shared cleaning pipeline ensures consistency</li> <li>Vectorization: TF-IDF transforms text to numerical features</li> <li>Classification: Baseline model produces probability distribution</li> <li>Uncertainty Handling: Low-confidence cases routed to LLM</li> <li>Output: Results delivered via CLI, UI, or JSON</li> </ol>"},{"location":"architecture/#technology-stack","title":"Technology Stack","text":"<ul> <li>Python 3.11+: Core language</li> <li>scikit-learn: ML framework</li> <li>llama-cpp-python: Local LLM inference</li> <li>Streamlit: Web UI framework</li> <li>Rich: Terminal formatting</li> <li>pytest: Testing framework</li> <li>MkDocs Material: Documentation</li> </ul> <p>See Model Information for ML details.</p>"},{"location":"cli/","title":"CLI Usage (NLPTriage)","text":"<p>The project ships with an enhanced CLI that behaves like a mini SOC assistant on the command line.</p> <p>It supports:</p> <ul> <li>NLPTriage ASCII banner</li> <li>Text cleaning preview</li> <li>Uncertainty-aware predictions (<code>uncertain</code> fallback)</li> <li>Difficulty modes (<code>--difficulty default|soc-medium|soc-hard</code>)</li> <li>MITRE ATT&amp;CK technique mapping panel</li> <li>Top\u2011k probability table (Rich table)</li> <li>Bulk file processing (<code>--file incidents.txt</code>)</li> <li>Batch summary report + recommendations</li> <li>Optional JSON output for automation</li> <li>Progress bar for all operations</li> <li>Interactive SOC\u2011style loop</li> </ul> <p>Install first</p> <p>Make sure you\u2019ve run:</p> <pre><code>pip install -e \".[dev]\"\n</code></pre> <p>from the project root so the package and entry points are available.</p>"},{"location":"cli/#basic-single-shot-usage","title":"Basic single-shot usage","text":"<p>From the repo root:</p> <pre><code>nlp-triage \"EDR detected powershell.exe spawning from Outlook on LAPTOP-093 and reaching out to 185.22.11.4 over port 443.\"\n</code></pre>"},{"location":"cli/#example-output","title":"Example output","text":""},{"location":"cli/#interactive-mode-usage","title":"Interactive mode usage","text":"<pre><code>nlp-triage\n</code></pre>"},{"location":"cli/#example-output_1","title":"Example output","text":""},{"location":"cli/#bulk-file-processing","title":"Bulk file processing","text":"<p>Provide a plain\u2011text file where each line is an incident description:</p> <pre><code>nlp-triage --file incidents.txt\n</code></pre> <p>Example preview:</p> <p> </p> <p>At the end of processing, NLPTriage prints a batch summary including: - Per\u2011class distribution - Most frequent MITRE techniques observed - Uncertain predictions count - Recommendations (e.g., raise threshold, retrain, add rules)</p>"},{"location":"cli/#how-it-works","title":"How it works","text":"<p>Each input is: - Cleaned using training\u2011consistent normalization - Vectorized using TF\u2011IDF model - Classified with uncertainty handling and difficulty rules - Mapped to MITRE ATT&amp;CK via keyword + heuristic extraction - Displayed using Rich panels for quick SOC triage</p>"},{"location":"cli/#uncertainty-thresholds","title":"Uncertainty &amp; thresholds","text":"<ul> <li><code>predict_with_uncertainty</code> compares the maximum class probability against <code>--threshold</code> (default 0.50).</li> <li>If the max probability is below the threshold, the CLI returns <code>final_label = \"uncertain\"</code> while still showing the <code>base_label</code>.</li> <li>A Rich panel labels each prediction as <code>low</code>, <code>medium</code>, or <code>high</code> certainty (color coded red/yellow/green) so analysts can gauge trust quickly.</li> <li>Use <code>--threshold 0.7</code> (or higher) when you only want confident predictions in automation workflows.</li> </ul>"},{"location":"cli/#difficulty-modes","title":"Difficulty Modes","text":"<p>You can control how strict MITRE matching and uncertainty logic behaves:</p> <pre><code>nlp-triage --difficulty soc-medium \"Suspicious PowerShell execution on host.\"\n</code></pre> <p>Modes: - default \u2014 balanced mode (recommended) - soc-medium \u2014 medium\u2011strict SOC mode (higher uncertainty marking) - soc-hard \u2014 strict SOC mode (very conservative, many predictions become 'uncertain')</p>"},{"location":"cli/#json-payload-schema","title":"JSON payload schema","text":"<p><code>--json</code> skips all Rich formatting and prints a dict with the following shape:</p> <pre><code>{\n  \"raw_text\": \"...\",\n  \"cleaned\": \"...\",\n  \"base_label\": \"phishing\",\n  \"final_label\": \"phishing\",\n  \"max_prob\": 0.83,\n  \"threshold\": 0.5,\n  \"uncertainty_level\": \"medium\",\n  \"difficulty\": \"default\",\n  \"mitre_techniques\": [\"T1566.002\"],\n  \"probs_sorted\": [...]\n}\n</code></pre> <p>This payload is what <code>tests/test_cli.py</code> asserts against, so you can rely on the keys staying stable even if the formatting evolves.</p>"},{"location":"cli/#mitre-attck-mapping","title":"MITRE ATT&amp;CK Mapping","text":"<p>The CLI enriches each prediction with a lightweight MITRE ATT&amp;CK\u00ae mapping based on the predicted <code>event_type</code>. This mapping is illustrative, not exhaustive, and is meant to provide quick pivot points for further analysis.</p> event_type ATT&amp;CK technique IDs <code>phishing</code> T1566 <code>malware</code> T1204, T1059, T1486 <code>web_attack</code> T1190, T1110 <code>access_abuse</code> T1078, T1110 <code>data_exfiltration</code> T1041, T1567 <code>policy_violation</code> T1052 <code>benign_activity</code> None (non-security / operational) <code>uncertain</code> None (requires analyst review) <p>In the CLI:</p> <ul> <li>The \u201cTop Class Probabilities\u201d table shows a <code>MITRE Techniques</code> column populated from this mapping.</li> <li>JSON / JSONL output includes:</li> <li><code>probs_sorted[*].mitre_techniques</code></li> <li><code>final_label_mitre_techniques</code> so downstream tools can pivot directly to ATT&amp;CK documentation.</li> </ul>"},{"location":"cli/#running-without-installing-entry-points","title":"Running without installing entry points","text":"<p>If <code>pip install -e .</code> is not available (e.g., in a quick experiment), you can invoke the CLI module directly after exporting <code>PYTHONPATH</code>:</p> <pre><code>PYTHONPATH=src python -m triage.cli \"Short incident description here.\"\n</code></pre> <p>Dependencies (<code>joblib</code>, <code>rich</code>, <code>scikit-learn</code>, etc.) still need to be available in the environment.</p>"},{"location":"cli/#help-menu","title":"Help menu","text":"<pre><code>nlp-triage -h\nusage: nlp-triage [-h] [--json] [--threshold THRESHOLD] [--max-classes MAX_CLASSES] [--difficulty {default,soc-medium,soc-hard}] [--input-file INPUT_FILE] [--output-file OUTPUT_FILE]\n                  [text]\n\nCybersecurity Incident NLP Triage CLI\n\npositional arguments:\n  text                  Incident description\n\noptions:\n  -h, --help            show this help message and exit\n  --json                Return raw JSON output instead of formatted text\n  --threshold THRESHOLD\n                        Uncertainty threshold (default=0.5)\n  --max-classes MAX_CLASSES\n                        Maximum number of classes to display in the probability table\n  --difficulty {default,soc-medium,soc-hard}\n                        Difficulty / strictness mode for uncertainty handling. Use 'soc-hard' to mark more cases as 'uncertain'.\n  --input-file INPUT_FILE\n                        Optional path to a text file for bulk mode; each non-empty line is treated as an incident description.\n  --output-file OUTPUT_FILE\n                        Optional path to write JSONL predictions for bulk mode. Each line will contain one JSON object.\n</code></pre>"},{"location":"configuration/","title":"Configuration","text":""},{"location":"configuration/#environment-variables","title":"Environment Variables","text":""},{"location":"configuration/#llm-configuration","title":"LLM Configuration","text":"<pre><code># Model path\nexport TRIAGE_LLM_MODEL=/path/to/llama-2-7b-chat.Q5_K_S.gguf\n\n# Generation settings\nexport NLP_TRIAGE_LLM_GENERATOR=1\nexport NLP_TRIAGE_LLM_REWRITE_PROB=0.30\nexport NLP_TRIAGE_LLM_TEMPERATURE=0.2\nexport NLP_TRIAGE_LLM_MAX_RETRIES=3\n\n# Debugging\nexport TRIAGE_LLM_DEBUG=1\n</code></pre>"},{"location":"configuration/#model-settings","title":"Model Settings","text":"<pre><code># Context window\nexport TRIAGE_LLM_CTX=4096\n\n# Max tokens for generation\nexport TRIAGE_LLM_MAX_TOKENS=512\n\n# Temperature (0.0-1.0)\nexport TRIAGE_LLM_TEMP=0.2\n</code></pre>"},{"location":"configuration/#cli-configuration","title":"CLI Configuration","text":""},{"location":"configuration/#uncertainty-thresholds","title":"Uncertainty Thresholds","text":"<pre><code># Default threshold\nnlp-triage --threshold 0.50 \"incident text\"\n\n# High confidence mode\nnlp-triage --threshold 0.70 \"incident text\"\n\n# Low confidence mode\nnlp-triage --threshold 0.30 \"incident text\"\n</code></pre>"},{"location":"configuration/#difficulty-modes","title":"Difficulty Modes","text":"<ul> <li><code>default</code> - Standard uncertainty handling</li> <li><code>soc-medium</code> - Moderate strictness</li> <li><code>soc-hard</code> - Maximum strictness for edge cases</li> </ul>"},{"location":"configuration/#streamlit-ui-configuration","title":"Streamlit UI Configuration","text":"<p>The UI respects the same environment variables as the CLI.</p>"},{"location":"configuration/#dataset-generation","title":"Dataset Generation","text":""},{"location":"configuration/#generation-parameters","title":"Generation Parameters","text":"<pre><code># In generate_cyber_incidents.py\n--n-events 50000           # Number of incidents\n--chunk-size 1000          # Checkpointing frequency\n--start-date 2024-01-01    # Date range start\n--end-date 2024-12-31      # Date range end\n--use-llm                  # Enable LLM rewriting\n--rewrite-report audit.json # LLM statistics output\n</code></pre> <p>See Production Generation for details.</p>"},{"location":"contributing/","title":"Contributing Guide","text":"<p>Coming Soon</p> <p>Detailed contribution guidelines are being developed.</p>"},{"location":"contributing/#quick-start","title":"Quick Start","text":"<ol> <li>Fork the repository</li> <li>Create a feature branch: <code>git checkout -b feature/amazing-feature</code></li> <li>Make your changes</li> <li>Run tests: <code>pytest tests/ -v</code></li> <li>Commit: <code>git commit -m 'Add amazing feature'</code></li> <li>Push: <code>git push origin feature/amazing-feature</code></li> <li>Open a Pull Request</li> </ol>"},{"location":"contributing/#development-setup","title":"Development Setup","text":"<pre><code>git clone https://github.com/YOUR_USERNAME/AlertSage.git\ncd AlertSage\npython -m venv .venv\nsource .venv/bin/activate\npip install -e \".[dev]\"\n</code></pre>"},{"location":"contributing/#code-style","title":"Code Style","text":"<ul> <li>Follow PEP 8</li> <li>Use type hints</li> <li>Add docstrings</li> <li>Write tests for new features</li> </ul>"},{"location":"contributing/#testing","title":"Testing","text":"<pre><code># Run all tests\npytest tests/ -v\n\n# Run specific test file\npytest tests/test_cli.py -v\n\n# With coverage\npytest tests/ --cov=src/triage\n</code></pre>"},{"location":"contributing/#documentation","title":"Documentation","text":"<pre><code># Preview docs locally\nmkdocs serve\n\n# Build docs\nmkdocs build\n</code></pre>"},{"location":"contributing/#pull-request-process","title":"Pull Request Process","text":"<ol> <li>Update documentation if needed</li> <li>Add tests for new functionality</li> <li>Ensure all tests pass</li> <li>Update CHANGELOG.md</li> <li>Request review from maintainers</li> </ol> <p>See Development Guide for more details.</p>"},{"location":"data-and-generator/","title":"Data &amp; Synthetic Generator","text":"<p>Understanding the dataset is critical for interpreting the model\u2019s behavior. Everything in this project is anchored on the synthetic CSV produced by <code>generator/generate_cyber_incidents.py</code>.</p>"},{"location":"data-and-generator/#dataset-overview","title":"Dataset overview","text":"<ul> <li>Path: <code>data/cyber_incidents_simulated.csv</code></li> <li>Default volume: 100,000 incidents spanning the 2024 calendar year</li> <li>Classes: <code>phishing</code>, <code>malware</code>, <code>access_abuse</code>, <code>data_exfiltration</code>, <code>policy_violation</code>, <code>web_attack</code>, <code>benign_activity</code></li> <li>Artifacts: All notebooks, the CLI, and the baseline model load from this CSV, so keep it in sync with any custom changes.</li> </ul>"},{"location":"data-and-generator/#schema-cheat-sheet","title":"Schema cheat sheet","text":"Column Description <code>event_id</code> Sequential identifier generated at write time <code>timestamp</code> Randomized datetime between 2024-01-01 and 2024-12-31 <code>log_source</code> Source system (email gateway, EDR, proxy, firewall, DLP, etc.) <code>event_type</code> One of the seven incident classes, optionally flipped for noise <code>severity</code> <code>info</code>\u2013<code>critical</code>, biased per event type (e.g., ransomware skews higher) <code>mitre_technique</code> Representative ATT&amp;CK technique(s) for that event <code>user</code>, <code>device</code> Named accounts and hosts targeted in the scenario <code>src_ip</code>, <code>dest_ip</code>, <code>src_country</code>, <code>dest_country</code> Network attribution fields <code>src_port</code>, <code>dest_port</code>, <code>protocol</code> Transport context tuned to the event type <code>detection_rule</code> Label for the analytic or alert that fired <code>is_true_positive</code> Simple flag indicating whether the scenario is a true incident <code>description</code> Full narrative with noise, typos, and abbreviated tokens <code>description_short</code> SOC-friendly summary <code>description_user_report</code> \u201cHow a user might describe it\u201d phrasing <code>short_log</code> WAF/SIEM style single-line log for quick scanning <p>Use the rich text fields (<code>description</code>, <code>description_short</code>, <code>description_user_report</code>, <code>short_log</code>) interchangeably across notebooks to test robustness against slightly different perspectives.</p>"},{"location":"data-and-generator/#realism-features-baked-into-the-generator","title":"Realism features baked into the generator","text":"<p>The <code>generate_cyber_incidents.py</code> script introduces several mechanisms to avoid a too-perfect dataset:</p> <ul> <li>Confusable classes: Sets such as <code>web_attack</code> vs <code>access_abuse</code> vs <code>benign_activity</code> share vocabulary on purpose.</li> <li>Label noise: <code>LABEL_NOISE_RATE</code> and <code>NEIGHBOR_LABELS</code> flip about 8\u202f% of labels to neighboring classes.</li> <li>Severity and MITRE biasing: Helper functions select severities, MITRE techniques, and log sources that match the event type.</li> <li>Narrative noise: Spelling swaps, abbreviations, and templated verbs keep <code>description</code> slightly messy while <code>description_short</code> stays concise.</li> <li>True/false positive signal: <code>is_true_positive</code> is biased toward <code>malware</code>, <code>data_exfiltration</code>, etc., so analysts can explore downstream filtering rules.</li> </ul> <p>These touches make downstream evaluation (confusion matrices, scenario notebooks, CLI uncertainty logic) feel closer to a real SOC dataset.</p>"},{"location":"data-and-generator/#regenerating-or-customizing-the-dataset","title":"Regenerating or customizing the dataset","text":"<ol> <li>Regenerate with defaults (100k rows to the same CSV):</li> </ol> <pre><code>python generator/generate_cyber_incidents.py\n</code></pre> <ol> <li>Customize volume or output path by calling <code>generate_events</code> directly:</li> </ol> <pre><code>python - &lt;&lt;'PY'\nfrom generator.generate_cyber_incidents import generate_events\ngenerate_events(n_events=25000, outfile=\"data/cyber_incidents_small.csv\")\nPY\n</code></pre> <ol> <li> <p>Tweak behavior inside <code>generator/generate_cyber_incidents.py</code>:</p> </li> <li> <p>Adjust <code>EVENT_TYPES</code> to add/remove classes.</p> </li> <li>Change <code>LABEL_NOISE_RATE</code>/<code>NEIGHBOR_LABELS</code> for more or less confusion.</li> <li>Extend vocab lists (<code>DETECTION_RULES</code>, <code>MALWARE_SUBTYPES</code>, etc.) to add new textures.</li> </ol> <p>Re-run any affected notebooks or retrain models after regenerating so artifacts remain consistent with the CSV on disk. The <code>tests/test_model_artifacts.py</code> suite will fail fast if the expected files or class labels go missing.</p>"},{"location":"data-and-generator/#production-generation-scripts","title":"Production Generation Scripts","text":"<p>For large-scale dataset generation (100K+ events) with LLM enhancement, checkpointing, and monitoring, the project includes professional bash orchestration scripts:</p>"},{"location":"data-and-generator/#quick-start","title":"Quick Start","text":"<pre><code># Launch 100K event generation (default)\ncd generator\n./launch_generator.sh\n\n# Monitor in real-time\n./monitor_generation.sh --watch\n</code></pre>"},{"location":"data-and-generator/#scripts-overview","title":"Scripts Overview","text":"Script Purpose <code>launch_generator.sh</code> Production launcher with LLM integration, checkpointing, background execution <code>monitor_generation.sh</code> Real-time monitoring dashboard with GPU metrics, throughput analysis, ETA calculation"},{"location":"data-and-generator/#key-features","title":"Key Features","text":"<p>launch_generator.sh:</p> <ul> <li>LLM Enhancement: Optional Llama-2-13B-Chat integration for realistic narrative rewrites (1% of events by default)</li> <li>Checkpoint/Resume: Automatic progress saving every 100 events - resume interrupted generations seamlessly</li> <li>Background Processing: Uses <code>nohup</code> for SSH-safe, unattended operation</li> <li>Interactive Resume: Prompts when existing files detected (resume vs fresh start)</li> <li>Environment Configuration: Automatically sets LLM model paths, rewrite probability, temperature</li> </ul> <p>monitor_generation.sh:</p> <ul> <li>Process Metrics: Real-time CPU/memory usage, runtime, efficiency (events/CPU%, events/GB)</li> <li>Progress Tracking: Visual progress bar, percentage complete, ETA with full timestamp</li> <li>GPU Acceleration (Apple Silicon): Metal GPU detection, LLM model info, inference speed (~18.5 tokens/sec)</li> <li>Throughput Analysis: Events/second average, trend detection (accelerating/declining/steady)</li> <li>Performance Dashboard: Chunk timing, last 5 log entries, file sizes, quick action commands</li> <li>Watch Mode: Auto-refresh every N seconds (default 30s)</li> <li>Simple Mode: ASCII symbols for problematic terminals (<code>--simple</code> or <code>--simple-color</code>)</li> </ul>"},{"location":"data-and-generator/#usage-examples","title":"Usage Examples","text":"<pre><code># Generate 50K events with custom name\n./launch_generator.sh 50000 training_data\n\n# Fresh start (delete existing files)\n./launch_generator.sh 100000 cyber_incidents_simulated --fresh\n\n# Monitor with auto-refresh every 10 seconds\n./monitor_generation.sh --watch 10\n\n# Monitor custom dataset in simple mode\n./monitor_generation.sh my_dataset --simple-color --watch\n</code></pre>"},{"location":"data-and-generator/#llm-configuration-in-launch_generatorsh","title":"LLM Configuration (in launch_generator.sh)","text":"<pre><code>export NLP_TRIAGE_LLM_GENERATOR=1             # Enable LLM generation\nexport NLP_TRIAGE_LLM_REWRITE_PROB=0.01       # 1% rewrite rate (balanced quality/speed)\nexport NLP_TRIAGE_LLM_TEMPERATURE=0.2         # Focused, deterministic output\nexport NLP_TRIAGE_LLM_MAX_RETRIES=3           # Retry failed LLM calls\nexport NLP_TRIAGE_LLM_BACKEND=\"models/llama-2-13b-chat.Q5_K_S.gguf\"\n</code></pre> <p>Performance:</p> <ul> <li>With LLM (1% rewrite): ~3-5 events/sec (100K events in 6-9 hours)</li> <li>Without LLM: ~50-100 events/sec (100K events in 20-30 minutes)</li> </ul>"},{"location":"data-and-generator/#output-files","title":"Output Files","text":"<p>All outputs written to <code>data/</code> directory:</p> File Description <code>{dataset_name}.csv</code> Main dataset (100K rows ~99MB uncompressed) <code>{dataset_name}.log</code> Detailed generation log with timestamps <code>{dataset_name}_checkpoint.json</code> Progress state for resume capability <code>{dataset_name}_llm_report.json</code> LLM usage statistics (rewrites attempted/applied, success rate, timing) <code>nohup_output.log</code> Raw stdout/stderr from background process"},{"location":"data-and-generator/#checkpointing-system","title":"Checkpointing System","text":"<p>Progress saved every 100 events:</p> <pre><code>{\n  \"last_completed_event\": 25000,\n  \"total_events\": 100000,\n  \"chunks_written\": 250,\n  \"timestamp\": \"2024-11-22T10:30:15\",\n  \"status\": \"running\"\n}\n</code></pre> <p>Resume behavior: Generator reads checkpoint, continues from <code>last_completed_event + 1</code>, appends to CSV without re-writing header.</p>"},{"location":"data-and-generator/#monitoring-dashboard-sample","title":"Monitoring Dashboard Sample","text":"<pre><code>\ud83d\udee0\ufe0f  CYBERSECURITY DATASET GENERATION MONITOR\nDataset: cyber_incidents_simulated\nStarted: Fri Nov 22 08:15:30 CST 2024\nETA: Fri Nov 22 14:32:15 CST 2024\n\n\ud83d\udcc8  PROCESS STATUS\n\u2705  Generation process RUNNING (PID: 12345)\n   CPU Usage: 125.3% (7.8% per core, 16 cores)\n   Memory Usage: 8.2% (2.1GB / 32.0GB)\n   \ud83c\udfae GPU: Metal (Apple M2 Max - 38 cores)\n      LLM Model: llama-2-13b-chat.Q5_K_S.gguf\n      Enhancement: 0.8% of events (99.4% success)\n      GPU Throughput: 375.2/hr (9.6s avg per rewrite)\n   Efficiency: 1,234 events/CPU%, 15,600 events/GB\n\n\ud83d\udcc8  PROGRESS STATUS\n\ud83d\ude80 25000/100000 (25.0%)\n   [\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2591\u2591\u2591\u2591\u2591\u2591\u2591\u2591\u2591\u2591\u2591\u2591\u2591\u2591\u2591\u2591\u2591\u2591\u2591\u2591\u2591\u2591\u2591\u2591\u2591\u2591\u2591\u2591] 25.0%\n   \ud83d\udcc8 Throughput: Steady\n\n\u26a1 PERFORMANCE\n   Generation runtime: 2h 15m 42s\n   Time per event: 0.3s\n   Events/second: 3.088\n   Estimated time remaining: 6h 15m\n</code></pre>"},{"location":"data-and-generator/#process-management","title":"Process Management","text":"<pre><code># Check if generation is running\npgrep -f \"generate_cyber_incidents.py\"\n\n# Kill running generation\npkill -f generate_cyber_incidents\n\n# View real-time logs\ntail -f data/cyber_incidents_simulated.log\n\n# Inspect checkpoint\ncat data/cyber_incidents_simulated_checkpoint.json | jq\n</code></pre>"},{"location":"data-and-generator/#customization","title":"Customization","text":"<p>Environment variables (set before launching):</p> <pre><code># Higher LLM rewrite rate (10% of events)\nexport NLP_TRIAGE_LLM_REWRITE_PROB=0.10\n\n# More creative LLM output\nexport NLP_TRIAGE_LLM_TEMPERATURE=0.7\n\n# Verbose LLM debugging\nexport NLP_TRIAGE_LLM_DEBUG=1\n\n# Custom model path\nexport NLP_TRIAGE_LLM_BACKEND=\"/path/to/custom-model.gguf\"\n</code></pre> <p>Direct Python call (manual control):</p> <pre><code>cd generator\npython generate_cyber_incidents.py \\\n  --n-events 50000 \\\n  --outfile ../data/my_dataset.csv \\\n  --start-date 2024-01-01 \\\n  --end-date 2024-12-31 \\\n  --chunk-size 100 \\\n  --use-llm \\\n  --rewrite-report ../data/my_dataset_llm_report.json\n</code></pre>"},{"location":"data-and-generator/#troubleshooting","title":"Troubleshooting","text":"<p>Slow generation: Lower <code>NLP_TRIAGE_LLM_REWRITE_PROB</code> (default 0.01 = 1%) or disable LLM entirely by commenting out <code>export NLP_TRIAGE_LLM_GENERATOR=1</code> in <code>launch_generator.sh</code>.</p> <p>Resume not working: Check checkpoint file exists (<code>ls -lh data/{dataset}_checkpoint.json</code>) and wasn't deleted. Ensure dataset name matches.</p> <p>Monitor shows \"No active generation\": Specify dataset name explicitly: <code>./monitor_generation.sh my_custom_dataset --watch</code></p> <p>LLM model not found: Download Llama-2-13B-Chat GGUF (Q5_K_S quantization, ~7.5GB) to <code>models/</code> directory, or disable LLM in launcher script.</p>"},{"location":"data-and-generator/#complete-documentation","title":"Complete Documentation","text":"<p>For comprehensive usage, GPU metrics, performance optimization, example workflows, and advanced configurations, see Production Generation Guide.</p>"},{"location":"development/","title":"Development","text":"<p>This page captures the day-to-day workflow for contributing changes, running tests, and keeping artifacts aligned with the codebase.</p>"},{"location":"development/#environment-installation","title":"Environment &amp; installation","text":"<ul> <li>Python 3.11+ is required (see <code>pyproject.toml</code>).</li> <li>Install the package in editable mode with dev extras:</li> </ul> <pre><code>pip install -e \".[dev]\"\n</code></pre> <p>This exposes the <code>nlp-triage</code> console script, installs <code>pytest</code>, and pulls in the runtime stack (<code>scikit-learn</code>, <code>pandas</code>, <code>rich</code>, etc.).</p> <ul> <li>Optional: if you prefer an isolated environment, create a <code>.venv</code> before installing (documented on the Getting Started page).</li> </ul>"},{"location":"development/#tests-continuous-integration","title":"Tests &amp; continuous integration","text":"<p>Pytest lives in <code>tests/</code> and exercises the three main building blocks:</p> Test module Focus area <code>tests/test_preprocess.py</code> Deterministic text cleaning rules (<code>triage.preprocess.clean_description</code>) <code>tests/test_model_artifacts.py</code> Ensures the saved TF\u2013IDF + Logistic Regression artifacts exist and can predict <code>tests/test_cli.py</code> Verifies CLI helpers return the expected prediction payload structure <p>Run the entire suite with:</p> <pre><code>pytest\n</code></pre> <p>CI simply mirrors this command. Keep artifacts (<code>models/vectorizer.joblib</code>, <code>models/baseline_logreg.joblib</code>) in sync with the dataset to avoid false negatives.</p>"},{"location":"development/#local-cli-notebook-checks","title":"Local CLI + notebook checks","text":"<ul> <li>CLI sanity check after making pipeline changes:</li> </ul> <pre><code>nlp-triage \"Employee forwarded an email that spoofs the VPN login page.\"\n</code></pre> <pre><code>Use `--threshold` and `--json` to stress uncertainty logic or automation scenarios (`docs/cli.md` dives deeper).\n</code></pre> <ul> <li>Notebook reproducibility:</li> <li>Run notebooks in order on the latest CSV to regenerate metrics and visuals (<code>docs/notebooks.md</code> lists the flow).</li> <li>Commit regenerated artifacts when you intentionally change training code; otherwise avoid stale diffs by reusing existing models/vectorizers.</li> </ul>"},{"location":"development/#documenting-and-serving-the-docs","title":"Documenting and serving the docs","text":"<ul> <li>All user-facing documentation lives in <code>docs/</code> and is wired up via <code>mkdocs.yml</code>.</li> <li>Preview local changes with:</li> </ul> <pre><code>mkdocs serve\n</code></pre> <p>(MkDocs Material is declared in <code>requirements.txt</code>; install it if you plan to live-preview docs.)</p>"},{"location":"development/#re-generating-data-or-models","title":"Re-generating data or models","text":"<ol> <li>Regenerate datasets via <code>generator/generate_cyber_incidents.py</code> (details on Data &amp; Synthetic Generator).</li> <li>Retrain models in <code>notebooks/03_baseline_model.ipynb</code> (and optional comparison notebooks).</li> <li>Copy the resulting <code>vectorizer.joblib</code> and <code>baseline_logreg.joblib</code> into <code>models/</code> so the CLI and tests pick them up.</li> </ol> <p>Whenever one of these steps changes, re-run <code>pytest</code> to ensure inference helpers still behave as expected.</p>"},{"location":"faq/","title":"Frequently Asked Questions","text":""},{"location":"faq/#general","title":"General","text":""},{"location":"faq/#what-is-this-project","title":"What is this project?","text":"<p>An educational cybersecurity triage platform demonstrating NLP-based incident classification with LLM enhancement and uncertainty-aware predictions.</p>"},{"location":"faq/#is-this-production-ready","title":"Is this production-ready?","text":"<p>No. This is designed for education, research, and portfolio demonstration. It requires evaluation on real data before operational use.</p>"},{"location":"faq/#can-i-use-this-in-my-soc","title":"Can I use this in my SOC?","text":"<p>Not without extensive testing and validation. Treat it as decision-support only, requiring human analyst oversight.</p>"},{"location":"faq/#technical","title":"Technical","text":""},{"location":"faq/#what-data-is-this-trained-on","title":"What data is this trained on?","text":"<p>Entirely synthetic data generated by the included scripts. Performance on real incidents is unknown.</p>"},{"location":"faq/#why-does-it-sometimes-say-uncertain","title":"Why does it sometimes say \"uncertain\"?","text":"<p>The model uses confidence thresholds to avoid low-quality predictions. \"Uncertain\" means manual review is recommended.</p>"},{"location":"faq/#how-do-i-improve-accuracy","title":"How do I improve accuracy?","text":"<ol> <li>Adjust confidence threshold</li> <li>Enable LLM second opinion</li> <li>Use difficulty mode for edge cases</li> <li>Train on real data (requires significant work)</li> </ol>"},{"location":"faq/#does-the-llm-send-data-externally","title":"Does the LLM send data externally?","text":"<p>No. All LLM inference uses local models via llama.cpp. No data leaves your machine.</p>"},{"location":"faq/#dataset-generation","title":"Dataset Generation","text":""},{"location":"faq/#how-long-does-generation-take","title":"How long does generation take?","text":"<ul> <li>Without LLM: ~2.5 hours for 50k incidents</li> <li>With 30% LLM: ~10 hours for 50k incidents</li> <li>Performance varies by hardware</li> </ul>"},{"location":"faq/#can-i-resume-interrupted-generation","title":"Can I resume interrupted generation?","text":"<p>Yes! The system uses checkpointing. Just rerun the launcher.</p>"},{"location":"faq/#what-if-i-run-out-of-disk-space","title":"What if I run out of disk space?","text":"<p>The dataset is ~2MB per 1000 incidents. Plan accordingly for large generations.</p>"},{"location":"faq/#llm-integration","title":"LLM Integration","text":""},{"location":"faq/#which-model-should-i-use","title":"Which model should I use?","text":"<p>Llama-2-7B-Chat (Q5_K_S) is recommended for balance of quality and speed.</p>"},{"location":"faq/#do-i-need-a-gpu","title":"Do I need a GPU?","text":"<p>No, but it helps. The system works on CPU, just slower.</p>"},{"location":"faq/#why-is-llm-inference-slow","title":"Why is LLM inference slow?","text":"<p>Local LLM inference is computationally intensive. Use quantized models and GPU acceleration when possible.</p>"},{"location":"faq/#cli-ui","title":"CLI &amp; UI","text":""},{"location":"faq/#how-do-i-enable-llm-in-the-cli","title":"How do I enable LLM in the CLI?","text":"<p>Use the <code>--llm-second-opinion</code> flag.</p>"},{"location":"faq/#can-i-process-multiple-incidents-at-once","title":"Can I process multiple incidents at once?","text":"<p>Yes! Use <code>--input-file</code> for bulk mode.</p>"},{"location":"faq/#how-do-i-get-json-output","title":"How do I get JSON output?","text":"<p>Add the <code>--json</code> flag.</p>"},{"location":"faq/#troubleshooting","title":"Troubleshooting","text":""},{"location":"faq/#model-files-not-found","title":"\"Model files not found\"","text":"<p>Run a notebook or test first - they trigger automatic dataset download.</p>"},{"location":"faq/#llm-import-failed","title":"\"LLM import failed\"","text":"<p>Install llama-cpp-python: <code>pip install llama-cpp-python</code></p>"},{"location":"faq/#out-of-memory-during-generation","title":"\"Out of memory during generation\"","text":"<p>Reduce LLM rewrite probability or chunk size.</p>"},{"location":"faq/#unexpected-label-in-llm-output","title":"\"Unexpected label in LLM output\"","text":"<p>This is normal - guardrails map variations to canonical labels.</p>"},{"location":"faq/#contributing","title":"Contributing","text":""},{"location":"faq/#how-can-i-contribute","title":"How can I contribute?","text":"<p>See Contributing Guide for details.</p>"},{"location":"faq/#where-do-i-report-bugs","title":"Where do I report bugs?","text":"<p>GitHub Issues</p>"},{"location":"faq/#can-i-add-new-features","title":"Can I add new features?","text":"<p>Yes! Fork, develop, test, and submit a pull request.</p> <p>Still have questions? Open a Discussion.</p>"},{"location":"getting-started/","title":"Getting Started","text":"<p>Follow these steps to install the project locally, run the CLI, and confirm everything is wired correctly.</p>"},{"location":"getting-started/#prerequisites","title":"Prerequisites","text":"<ul> <li>Python 3.11 or newer</li> <li>Git</li> <li>(Recommended) A virtual environment tool such as <code>venv</code></li> </ul>"},{"location":"getting-started/#1-clone-the-repository","title":"1. Clone the repository","text":"<pre><code>git clone https://github.com/texasbe2trill/AlertSage.git\ncd AlertSage\n</code></pre>"},{"location":"getting-started/#2-create-activate-a-virtual-environment","title":"2. Create &amp; activate a virtual environment","text":"<pre><code>python -m venv .venv\nsource .venv/bin/activate  # macOS / Linux\n# .venv\\Scripts\\activate   # Windows PowerShell\n</code></pre> <p>Any Python env tool works; <code>.venv</code> just keeps dependencies isolated from your system install.</p>"},{"location":"getting-started/#3-install-the-package-with-dev-extras","title":"3. Install the package (with dev extras)","text":"<pre><code>pip install -e \".[dev]\"\n</code></pre> <p>This editable install exposes the <code>nlp-triage</code> CLI and pulls dev dependencies (Pytest) listed in <code>pyproject.toml</code>.</p>"},{"location":"getting-started/#4-verify-model-artifacts-cli","title":"4. Verify model artifacts + CLI","text":"<p>Models and vectorizer are stored in:</p> <pre><code>models/\n\u251c\u2500\u2500 vectorizer.joblib\n\u2514\u2500\u2500 baseline_logreg.joblib\n</code></pre> <p>Quick confidence checks:</p> <pre><code># Ensure artifacts load without errors\npython -c \"from triage.model import load_vectorizer_and_model; print(load_vectorizer_and_model()[0].__class__)\"\n\n# Run a single-shot CLI prediction\nnlp-triage \"User reported a suspicious payroll login email with a fake link.\"\n</code></pre> <p>For JSON output (useful for automation testing):</p> <pre><code>nlp-triage --json \"VPN portal prompted for re-authentication and asked for MFA reset.\"\n</code></pre> <p>Screenshots of the formatted output live in <code>docs/images/</code>.</p>"},{"location":"getting-started/#5-run-the-unit-tests","title":"5. Run the unit tests","text":"<pre><code>pytest\n</code></pre> <p>See Development for a breakdown of what each test covers.</p>"},{"location":"getting-started/#optional-next-steps","title":"Optional next steps","text":"<ul> <li>Regenerate data via <code>python generator/generate_cyber_incidents.py</code> (details on Data &amp; Synthetic Generator).</li> <li>Explore notebooks under <code>notebooks/</code> to retrace the modeling workflow.</li> <li>Preview docs while editing by running <code>mkdocs serve</code>.</li> </ul>"},{"location":"glossary/","title":"Glossary","text":""},{"location":"glossary/#terms","title":"Terms","text":""},{"location":"glossary/#checkpoint","title":"Checkpoint","text":"<p>Persistent state file enabling resumable dataset generation. Contains progress, timestamps, and metadata.</p>"},{"location":"glossary/#confidence-threshold","title":"Confidence Threshold","text":"<p>Minimum probability score required for a label. Below threshold triggers \"uncertain\" fallback.</p>"},{"location":"glossary/#difficulty-mode","title":"Difficulty Mode","text":"<p>Setting controlling strictness of uncertainty handling:</p> <ul> <li>default: Standard thresholds</li> <li>soc-medium: Moderate strictness</li> <li>soc-hard: Maximum strictness for edge cases</li> </ul>"},{"location":"glossary/#gguf","title":"GGUF","text":"<p>GPT-Generated Unified Format. File format for quantized LLM models used by llama.cpp.</p>"},{"location":"glossary/#guardrails","title":"Guardrails","text":"<p>Safety mechanisms preventing LLM hallucinations:</p> <ul> <li>JSON parsing validation</li> <li>SOC keyword intelligence</li> <li>Label normalization</li> <li>Timeout protection</li> </ul>"},{"location":"glossary/#incident","title":"Incident","text":"<p>Security event requiring investigation. Represented as natural language narrative in this system.</p>"},{"location":"glossary/#llm","title":"LLM","text":"<p>Large Language Model. Used for dataset enhancement and second-opinion triage.</p>"},{"location":"glossary/#mitre-attck","title":"MITRE ATT&amp;CK\u00ae","text":"<p>Knowledge base of adversary tactics and techniques. Used for incident enrichment and mapping.</p>"},{"location":"glossary/#quantization","title":"Quantization","text":"<p>Model compression technique reducing size/memory at slight accuracy cost (Q4, Q5, Q8).</p>"},{"location":"glossary/#rewrite-engine","title":"Rewrite Engine","text":"<p>LLM-powered component enhancing synthetic narratives during generation.</p>"},{"location":"glossary/#second-opinion","title":"Second Opinion","text":"<p>LLM-assisted classification for uncertain cases. Provides alternative perspective with rationale.</p>"},{"location":"glossary/#soc","title":"SOC","text":"<p>Security Operations Center. Team responsible for monitoring and responding to security incidents.</p>"},{"location":"glossary/#synthetic-data","title":"Synthetic Data","text":"<p>Artificially generated training data. This project uses 100% synthetic incidents.</p>"},{"location":"glossary/#tf-idf","title":"TF-IDF","text":"<p>Term Frequency-Inverse Document Frequency. Statistical measure for text feature extraction.</p>"},{"location":"glossary/#triage","title":"Triage","text":"<p>Process of categorizing and prioritizing incidents based on severity and type.</p>"},{"location":"glossary/#uncertain","title":"Uncertain","text":"<p>Label assigned when classifier confidence is below threshold. Indicates manual review needed.</p>"},{"location":"glossary/#vectorization","title":"Vectorization","text":"<p>Conversion of text to numerical representations for ML processing.</p>"},{"location":"glossary/#acronyms","title":"Acronyms","text":"Acronym Full Term API Application Programming Interface ATT&amp;CK Adversarial Tactics, Techniques &amp; Common Knowledge CI/CD Continuous Integration/Continuous Deployment CLI Command-Line Interface CPU Central Processing Unit CSV Comma-Separated Values EDR Endpoint Detection and Response ETA Estimated Time of Arrival GGUF GPT-Generated Unified Format GPU Graphics Processing Unit IR Incident Response JSON JavaScript Object Notation JSONL JSON Lines (one JSON object per line) LLM Large Language Model MITRE Massachusetts Institute of Technology Research and Engineering ML Machine Learning NLP Natural Language Processing RAM Random Access Memory SIEM Security Information and Event Management SOAR Security Orchestration, Automation and Response SOC Security Operations Center TF-IDF Term Frequency-Inverse Document Frequency UI User Interface URL Uniform Resource Locator"},{"location":"glossary/#file-extensions","title":"File Extensions","text":"Extension Description <code>.csv</code> Comma-separated values dataset file <code>.joblib</code> Serialized scikit-learn model or vectorizer <code>.json</code> JSON configuration or results file <code>.jsonl</code> JSON Lines (bulk results, one record per line) <code>.log</code> Text log file <code>.md</code> Markdown documentation file <code>.gguf</code> Quantized LLM model file <code>.py</code> Python source code file <code>.sh</code> Shell script file <code>.yml</code> YAML configuration file <p>For technical terms, see Architecture and Model Information.</p>"},{"location":"limitations/","title":"Limitations &amp; Safety","text":"<p>Educational / research-grade only</p> <p>This project is intended for learning, experimentation, and portfolio use. It is not designed or validated as production incident response tooling.</p>"},{"location":"limitations/#key-limitations","title":"Key Limitations","text":"<ul> <li> <p>Synthetic-only training   The model is trained entirely on synthetic incidents. While carefully designed, they do not fully capture the variability, noise, and corner cases of real SOC tickets and alerts.</p> </li> <li> <p>Misclassification of edge cases   Borderline or cleverly worded narratives may be misclassified. Some classes naturally overlap (e.g., <code>data_exfiltration</code> vs <code>policy_violation</code>, <code>web_attack</code> vs <code>benign_activity</code>).</p> </li> <li> <p>Not for unsupervised live use   The CLI is designed as a decision-support aid and educational demo, not as an unsupervised gatekeeper for real-world security decisions.</p> </li> <li> <p>No real-time integration   There is no direct integration with SIEM/EDR/SOAR platforms; any such integration would require additional engineering, monitoring, and governance.</p> </li> </ul>"},{"location":"limitations/#recommended-usage","title":"Recommended Usage","text":"<ul> <li>Use as a sandbox for experimenting with:</li> <li>Synthetic data generation</li> <li>NLP modeling patterns</li> <li>Evaluation frameworks and scenario-based testing</li> <li>Treat model outputs as advisory hints, not final ground truth.</li> <li>If you adapt this for real-world use, involve:</li> <li>Security engineers and incident responders</li> <li>MLOps and governance teams</li> <li>Rigorous validation with real data and monitoring</li> </ul>"},{"location":"llm-integration/","title":"LLM Integration","text":""},{"location":"llm-integration/#overview","title":"Overview","text":"<p>The project uses llama.cpp for privacy-first local LLM inference in two key areas:</p> <ol> <li>Dataset Generation - Enhancing synthetic narratives</li> <li>Second-Opinion Triage - Assisting with uncertain classifications</li> </ol>"},{"location":"llm-integration/#setup","title":"Setup","text":""},{"location":"llm-integration/#install-llama-cpp-python","title":"Install llama-cpp-python","text":"<pre><code># For Apple Silicon (Metal acceleration)\nCMAKE_ARGS=\"-DLLAMA_METAL=on\" pip install llama-cpp-python\n\n# For CUDA GPUs\nCMAKE_ARGS=\"-DLLAMA_CUDA=on\" pip install llama-cpp-python\n\n# CPU only\npip install llama-cpp-python\n</code></pre>"},{"location":"llm-integration/#download-model","title":"Download Model","text":"<p>Choose a GGUF model and download via Hugging Face CLI (authenticate if required):</p> <pre><code># Create models directory\nmkdir -p models\n\n# Option A: Llama 3.1 8B Instruct (higher quality)\nhuggingface-cli download TheBloke/Llama-3.1-8B-Instruct-GGUF \\\n  Llama-3.1-8B-Instruct-Q6_K.gguf --local-dir models\n\n# Option B: Mistral 7B Instruct v0.2 (mid-size)\nhuggingface-cli download TheBloke/Mistral-7B-Instruct-v0.2-GGUF \\\n  mistral-7b-instruct-v0.2.Q6_K.gguf --local-dir models\n\n# Option C: TinyLlama 1.1B Chat (small, CPU-friendly)\nhuggingface-cli download TinyLlama/TinyLlama-1.1B-Chat-v1.0-GGUF \\\n  TinyLlama-1.1B-Chat-v1.0.Q6_K.gguf --local-dir models\n</code></pre>"},{"location":"llm-integration/#configure-environment","title":"Configure Environment","text":"<pre><code># Preferred (CLI):\nexport TRIAGE_LLM_MODEL=\"$(pwd)/models/Llama-3.1-8B-Instruct-Q6_K.gguf\"\nexport TRIAGE_LLM_DEBUG=1\n\n# Alternative (library client compatibility):\nexport NLP_TRIAGE_LLM_BACKEND=\"$TRIAGE_LLM_MODEL\"\n</code></pre>"},{"location":"llm-integration/#dataset-generation","title":"Dataset Generation","text":""},{"location":"llm-integration/#enable-llm-rewriting","title":"Enable LLM Rewriting","text":"<pre><code>python generator/generate_cyber_incidents.py \\\n  --n-events 5000 \\\n  --use-llm \\\n  --rewrite-report audit.json\n</code></pre>"},{"location":"llm-integration/#rewrite-parameters","title":"Rewrite Parameters","text":"<pre><code>export NLP_TRIAGE_LLM_REWRITE_PROB=0.30  # 30% of incidents rewritten\nexport NLP_TRIAGE_LLM_TEMPERATURE=0.2     # Focused generation\nexport NLP_TRIAGE_LLM_MAX_RETRIES=3       # Error recovery\n</code></pre>"},{"location":"llm-integration/#how-it-works","title":"How It Works","text":"<ol> <li>Generator creates baseline narrative</li> <li>LLM probabilistically rewrites (30% by default)</li> <li>Sanitization removes artifacts</li> <li>Validation ensures quality</li> <li>Audit log tracks statistics</li> </ol>"},{"location":"llm-integration/#second-opinion-triage","title":"Second-Opinion Triage","text":""},{"location":"llm-integration/#cli-usage","title":"CLI Usage","text":"<pre><code># Single incident\nnlp-triage --llm-second-opinion \"Suspicious activity detected\"\n\n# Bulk processing\nnlp-triage --llm-second-opinion \\\n  --input-file incidents.txt \\\n  --output-file results.jsonl\n</code></pre>"},{"location":"llm-integration/#streamlit-ui","title":"Streamlit UI","text":"<p>Enable \"LLM Second Opinion\" toggle in the sidebar.</p>"},{"location":"llm-integration/#guardrails","title":"Guardrails","text":"<p>The second-opinion engine includes multiple safety layers:</p> <ol> <li>JSON Parsing - Structured output validation</li> <li>SOC Keyword Intelligence - Domain-specific validation</li> <li>Label Normalization - Maps variations to canonical labels</li> <li>Confidence Filtering - Only engages on uncertain cases</li> <li>Timeout Protection - Prevents hanging on bad inputs</li> </ol>"},{"location":"llm-integration/#advanced-configuration","title":"Advanced Configuration","text":""},{"location":"llm-integration/#model-parameters","title":"Model Parameters","text":"<pre><code># Context window (tokens)\nexport TRIAGE_LLM_CTX=4096\n\n# Max generation tokens\nexport TRIAGE_LLM_MAX_TOKENS=512\n\n# Temperature (creativity)\nexport TRIAGE_LLM_TEMP=0.2\n\n# Top-p sampling\nexport TRIAGE_LLM_TOP_P=0.9\n</code></pre>"},{"location":"llm-integration/#backend-selection","title":"Backend Selection","text":"<pre><code># Absolute path to model\nexport NLP_TRIAGE_LLM_BACKEND=/full/path/to/model.gguf\n</code></pre>"},{"location":"llm-integration/#performance-tuning","title":"Performance Tuning","text":""},{"location":"llm-integration/#cpu-optimization","title":"CPU Optimization","text":"<pre><code># Increase thread count\nexport OMP_NUM_THREADS=8\n\n# Use BLAS\nCMAKE_ARGS=\"-DLLAMA_BLAS=ON\" pip install llama-cpp-python\n</code></pre>"},{"location":"llm-integration/#gpu-acceleration","title":"GPU Acceleration","text":"<pre><code># CUDA\nCMAKE_ARGS=\"-DLLAMA_CUDA=on\" pip install llama-cpp-python\n\n# Metal (Apple Silicon)\nCMAKE_ARGS=\"-DLLAMA_METAL=on\" pip install llama-cpp-python\n</code></pre>"},{"location":"llm-integration/#memory-management","title":"Memory Management","text":"<pre><code># Reduce context for lower memory\nexport TRIAGE_LLM_CTX=2048\n\n# Use quantized models (Q4, Q5)\n# Smaller = less accurate but faster\n</code></pre>"},{"location":"llm-integration/#troubleshooting","title":"Troubleshooting","text":""},{"location":"llm-integration/#import-errors","title":"Import Errors","text":"<pre><code># Reinstall with correct flags\npip uninstall llama-cpp-python\nCMAKE_ARGS=\"-DLLAMA_METAL=on\" pip install llama-cpp-python\n</code></pre>"},{"location":"llm-integration/#slow-inference","title":"Slow Inference","text":"<ul> <li>Use quantized models (Q5_K_S recommended)</li> <li>Enable GPU acceleration</li> <li>Reduce context window</li> <li>Lower max tokens</li> </ul>"},{"location":"llm-integration/#out-of-memory","title":"Out of Memory","text":"<ul> <li>Use smaller model (7B instead of 13B)</li> <li>Reduce context window</li> <li>Close other applications</li> </ul>"},{"location":"llm-integration/#debug-mode","title":"Debug Mode","text":"<pre><code>export TRIAGE_LLM_DEBUG=1\nnlp-triage --llm-second-opinion \"test incident\"\n</code></pre>"},{"location":"llm-integration/#best-practices","title":"Best Practices","text":"<p>\u2705 Use quantized models (Q5_K_S or Q4_K_M) \u2705 Enable GPU acceleration when available \u2705 Set appropriate context window for your RAM \u2705 Monitor resource usage during generation \u2705 Use lower temperature for focused outputs \u2705 Enable debug mode for troubleshooting</p> <p>\u274c Don't use unquantized models (too large) \u274c Don't set context &gt; 8192 without sufficient RAM \u274c Don't ignore timeout warnings \u274c Don't disable guardrails in production</p> <p>See Production Generation for monitoring LLM-enhanced dataset creation.</p>"},{"location":"mitre-attribution/","title":"MITRE ATT&amp;CK\u00ae Attribution","text":"<p>This project makes limited, research-focused use of the MITRE ATT&amp;CK\u00ae knowledge base.</p> <p>Specifically, the synthetic incident generator and modeling notebooks:</p> <ul> <li>Reference ATT&amp;CK technique IDs (for example, <code>T1078</code>, <code>T1190</code>, <code>T1486</code>, <code>T1566</code>),</li> <li>Include lightly paraphrased language inspired by public ATT&amp;CK technique descriptions,</li> <li>Use these techniques to make simulated adversary behavior more realistic in narrative text fields.</li> </ul> <p>No proprietary or internal threat intel is used; all references are drawn from publicly available ATT&amp;CK content and are intended for educational and portfolio purposes only.</p>"},{"location":"mitre-attribution/#trademarks-and-license","title":"Trademarks and license","text":"<p>MITRE ATT&amp;CK\u00ae and ATT&amp;CK\u00ae are registered trademarks of The MITRE Corporation.</p> <p>ATT&amp;CK data is provided by The MITRE Corporation and is licensed under the Creative Commons Attribution-ShareAlike 4.0 International License (CC BY-SA 4.0).</p> <p>For full details, see the official MITRE ATT&amp;CK site and licensing information.</p>"},{"location":"mitre-attribution/#how-this-project-uses-attck","title":"How this project uses ATT&amp;CK","text":"<p>Within this repository, ATT&amp;CK references primarily appear in:</p> <ul> <li>The synthetic data generator (<code>generator/generate_cyber_incidents.py</code>), where certain   narratives add clauses such as \"This behavior aligns with MITRE ATT&amp;CK technique T1486\"   to emulate analyst-style writeups.</li> <li>Modeling and evaluation notebooks, which occasionally refer to relevant tactics or   techniques when discussing example incidents or patterns (for example, ransomware   encryption mapped to <code>T1486</code>, phishing mapped to <code>T1566</code>, or web exploitation mapped   to <code>T1190</code>).</li> </ul> <p>These references are contextual aids to make the simulated incidents feel more SOC-realistic and to help readers connect incident categories to canonical ATT&amp;CK techniques. They are not intended to be authoritative mappings and should not be used as the sole basis for production detection logic.</p>"},{"location":"mitre-attribution/#scope-and-limitations","title":"Scope and limitations","text":"<ul> <li>The dataset is synthetic and only loosely aligned to ATTATT&amp;CK many edge cases and   real-world nuances are intentionally simplified.</li> <li>Technique IDs included in narratives are examples rather than exhaustive coverage.</li> <li>This repository does not redistribute the full ATT&amp;CK corpus; it only uses short   paraphrased clauses and technique IDs.</li> </ul> <p>If you use this project in your own work, please ensure that any further use of ATT&amp;CK content continues to respect MITRE's licensing and trademark guidance.</p>"},{"location":"model-information/","title":"Model Information","text":""},{"location":"model-information/#model-card-nlp-incident-triage-v020","title":"\ud83d\udcc4 Model Card \u2014 NLP Incident Triage (v0.2.0)","text":"<p>Model Name: NLP Incident Triage Version: 0.2.0 Author: Chris Campbell (@texasbe2trill) Intended Use: Educational and research-grade NLP classifier trained on synthetic cybersecurity incident narratives. Designed to demonstrate SOC triage automation concepts\u2014not to replace production security tooling.</p>"},{"location":"model-information/#1-model-description","title":"1. Model Description","text":"<p>A TF\u2013IDF + Logistic Regression classifier that assigns cybersecurity incident narratives to high-level event types:</p> <pre><code>phishing  \nmalware  \naccess_abuse  \ndata_exfiltration  \npolicy_violation  \nweb_attack  \nbenign_activity\n</code></pre> <p>The model uses: - Synthetic SOC-style data with narrative templates - MITRE ATT&amp;CK\u2013inspired phrasing - Noise injection + label flipping for realism - Uncertainty-aware predictions (<code>uncertain</code> fallback) - Difficulty modes (<code>soc-medium</code>, <code>soc-hard</code>)  </p>"},{"location":"model-information/#2-intended-use","title":"2. Intended Use","text":"<p>The model is suitable for:</p> <ul> <li>Demonstrating NLP-based SOC triage workflows  </li> <li>Academic or training environments  </li> <li>Research on text classification methods  </li> <li>Early-stage prototyping of incident summarization/triage tools  </li> </ul>"},{"location":"model-information/#3-not-intended-for","title":"3. Not Intended For","text":"<p>Not for production SOC or IR operations. Not designed for automated high-stakes decisions. Not trained on real security logs.</p>"},{"location":"model-information/#4-training-data","title":"4. Training Data","text":"<ul> <li>100% synthetic dataset  </li> <li>Multiple event types with realistic SOC-style variation  </li> <li>Includes ambiguous scenarios and misdirection  </li> <li>MITRE-inspired narrative segments (Technique IDs included as text)  </li> <li>No PII, customer data, or proprietary logs  </li> </ul>"},{"location":"model-information/#5-evaluation","title":"5. Evaluation","text":"<p>Evaluated using:</p> <ul> <li>Synthetic hold\u2011out test set  </li> <li>18\u2011scenario SOC test suite  </li> <li>Ambiguity stress tests  </li> <li>Model comparison across LogReg, Linear SVM, RandomForest  </li> <li>Probability calibration analysis  </li> </ul> <p>Observed behavior:</p> <ul> <li>~92% accuracy on synthetic test set  </li> <li>Strong performance on clear-cut phishing/malware/exfiltration  </li> <li>Realistic degradation on ambiguous or noisy cases  </li> <li>Uncertainty thresholding improves stability  </li> </ul>"},{"location":"model-information/#6-ethical-considerations","title":"6. Ethical Considerations","text":"<ul> <li>Only synthetic data used  </li> <li>No real-world adversary emulation  </li> <li>User should maintain human-in-the-loop validation  </li> <li>MITRE ATT&amp;CK\u00ae used with required attribution:</li> <li>\u201cMITRE ATT&amp;CK\u00ae is a registered trademark of The MITRE Corporation.\u201d</li> </ul>"},{"location":"model-information/#7-limitations","title":"7. Limitations","text":"<ul> <li>Not trained on real logs or telemetry  </li> <li>Cannot detect rare SOC events outside template patterns  </li> <li>Limited ability to reason over long multi-sentence reports  </li> <li>Vocabulary tied to generator styles  </li> </ul>"},{"location":"model-information/#8-recommendations-for-future-work","title":"8. Recommendations for Future Work","text":"<ul> <li>Expand training set with richer MITRE-derived semantics  </li> <li>Add vendor-specific log styles (MDE, CrowdStrike, Okta, etc.)  </li> <li>Introduce structured indicators (IPs, ports, geodata) as model features  </li> <li>Explore transformer-based encoders for long-text handling  </li> <li>Increase scenario test suite to 50+ cases  </li> </ul>"},{"location":"model-information/#9-version-history","title":"9. Version History","text":""},{"location":"model-information/#v020","title":"v0.2.0","text":"<ul> <li>MITRE-inspired narrative enrichment  </li> <li>Difficulty modes (<code>soc-medium</code>, <code>soc-hard</code>)  </li> <li>Bulk analysis mode  </li> <li>SOC summary output  </li> <li>Improved CLI formatting and progress bar  </li> <li>Updated documentation and model card  </li> </ul> <p>If you would like, I can also generate a printable PDF version of this model card for inclusion in releases.</p>"},{"location":"modeling-and-eval/","title":"Modeling &amp; Evaluation","text":""},{"location":"modeling-and-eval/#text-representation","title":"Text Representation","text":"<p>The baseline models use TF\u2013IDF over cleaned incident descriptions:</p> <ul> <li>Unigrams + bigrams</li> <li>English stopword removal</li> <li><code>min_df</code> and <code>max_df</code> thresholds to drop extremely rare / frequent terms</li> <li>Max feature cap (e.g., 5,000 terms)</li> </ul> <p>Cleaning is shared between training and inference via <code>triage.preprocess.clean_description</code>.</p>"},{"location":"modeling-and-eval/#models-compared","title":"Models compared","text":"<p>Notebook 08_Model_Comparison trains and compares several models:</p> <ul> <li><code>logreg_baseline</code> \u2014 Logistic Regression (multi-class, one-vs-rest)</li> <li><code>linear_svm</code> \u2014 Linear SVM classifier</li> <li><code>random_forest</code> \u2014 Random Forest over TF\u2013IDF features</li> </ul> <p>On the synthetic test set (~20k rows), these models all achieve around 92% accuracy, with:</p> <ul> <li>High precision/recall for clear-cut classes (<code>phishing</code>, <code>malware</code>, <code>web_attack</code>, <code>data_exfiltration</code>)</li> <li>Lower but still strong performance on more ambiguous narratives (<code>benign_activity</code>, overlapping <code>policy_violation</code> scenarios)</li> </ul>"},{"location":"modeling-and-eval/#scenario-based-evaluation","title":"Scenario-based evaluation","text":"<p>Notebook 07_Scenario_Based_Evaluation:</p> <ul> <li>Tests the model on hand-crafted narratives that look like real tickets or alerts</li> <li>Compares expected event_type vs model prediction</li> <li>Surfaces realistic errors:</li> <li>Some benign operations labeled as <code>web_attack</code> or <code>policy_violation</code></li> <li>Some policy violations near data movement labeled as <code>data_exfiltration</code></li> <li>Borderline authentication issues split between <code>access_abuse</code> and <code>benign_activity</code></li> </ul> <p>This helps validate that the model is learning semantically meaningful patterns rather than just memorizing templates.</p>"},{"location":"modeling-and-eval/#training-artifacts-reproducibility","title":"Training artifacts &amp; reproducibility","text":"<ul> <li>Notebooks 02\u201304 export <code>models/vectorizer.joblib</code> and <code>models/baseline_logreg.joblib</code>.</li> <li><code>triage.model.load_vectorizer_and_model()</code> (used by the CLI and tests) expects those filenames, so keep them consistent.</li> <li>To experiment with alternate classifiers, either:</li> <li>Update <code>notebooks/08_model_comparison.ipynb</code> and drop extra <code>.joblib</code> files next to the baseline, or</li> <li>Edit <code>src/triage/model.py</code> / <code>src/triage/cli.py</code> to point at the new artifact names.</li> <li>The CLI always calls <code>predict_proba</code>, so stick to classifiers that expose that method or wrap them with <code>CalibratedClassifierCV</code>.</li> </ul>"},{"location":"modeling-and-eval/#takeaways","title":"Takeaways","text":"<ul> <li>TF\u2013IDF + simple linear models can perform surprisingly well on structured, synthetic incident narratives.</li> <li>For real SOC deployment, you would likely:</li> <li>Incorporate structured features (severity, log source, time of day, etc.)</li> <li>Move to transformer-based embeddings</li> <li>Tighten evaluation on true production tickets</li> </ul> <p>When experimenting, rerun the <code>pytest</code> suite to confirm the refreshed artifacts still contain the expected class labels.</p>"},{"location":"notebooks/","title":"Notebooks Overview","text":"<p>The project includes 11 comprehensive Jupyter notebooks covering the complete machine learning pipeline from getting started through production-ready hybrid models. Each notebook has been enhanced with professional visualizations, comprehensive markdown analysis, and practical insights.</p>"},{"location":"notebooks/#notebook-sequence","title":"Notebook Sequence","text":""},{"location":"notebooks/#0-00_getting_started_tutorialipynb-interactive-getting-started-guide-start-here","title":"0. 00_getting_started_tutorial.ipynb - Interactive Getting Started Guide \u2b50 START HERE","text":"<p>Purpose: Beginner-friendly interactive tutorial introducing AlertSage fundamentals for new users and contributors.</p> <p>Key Features:</p> <ul> <li>Environment Setup: Verification of Python, packages, models, and dataset</li> <li>Model Loading: Load pre-trained TF-IDF vectorizer and baseline logistic regression</li> <li>First Prediction: Step-by-step walkthrough of single incident analysis</li> <li>Batch Processing: Analyze 30 diverse incidents across all 10 event types</li> <li>4 Interactive Visualizations:</li> <li>Class distribution bar chart</li> <li>Confidence score histogram with uncertainty threshold</li> <li>Confidence by event type box plots</li> <li>Confusion matrix heatmap</li> <li>Uncertainty Analysis: Understanding confidence thresholds (50%, 60%, 75%)</li> <li>LLM Integration: Conceptual overview of ML+LLM hybrid approach</li> <li>3 Hands-On Exercises: Custom incident analysis, threshold experimentation, problematic case identification</li> <li>Next Steps Guide: Links to advanced notebooks, CLI usage, Streamlit UI, and documentation</li> </ul> <p>Learning Outcomes: Understand incident triage workflow, interpret confidence scores, create visualizations, recognize when LLM assistance is needed, practice with real scenarios.</p>"},{"location":"notebooks/#1-01_explore_datasetipynb-dataset-exploration-quality-assessment","title":"1. 01_explore_dataset.ipynb - Dataset Exploration &amp; Quality Assessment","text":"<p>Purpose: Comprehensive exploratory data analysis (EDA) of the synthetic cybersecurity incident dataset.</p> <p>Key Features:</p> <ul> <li>Event Type Distribution: Color-coded bar charts showing class balance</li> <li>Temporal Analysis: Incident distribution across 2024 with seasonal patterns</li> <li>Severity Assessment: Stacked bar charts showing severity levels per event type</li> <li>Log Source Analysis: Detection system coverage visualizations</li> <li>Geographic Distribution: Source/destination country analysis</li> <li>MITRE ATT&amp;CK Mapping: Technique distribution across incident classes</li> </ul> <p>Learning Outcomes: Understand dataset balance, temporal patterns, severity biasing, and log source diversity.</p>"},{"location":"notebooks/#2-02_prepare_text_and_featuresipynb-feature-engineering-text-preprocessing","title":"2. 02_prepare_text_and_features.ipynb - Feature Engineering &amp; Text Preprocessing","text":"<p>Purpose: Transform raw text descriptions into TF-IDF feature matrices.</p> <p>Key Features:</p> <ul> <li>Text cleaning pipeline (lowercase, punctuation removal)</li> <li>TF-IDF vectorization (max_features=3000, min_df=2)</li> <li>Feature sparsity analysis and vocabulary composition charts</li> <li>Stratified 80/20 train/test split</li> <li>Artifact export (vectorizer, matrices) to <code>models/</code></li> </ul> <p>Learning Outcomes: Master TF-IDF sparse matrices, scikit-learn pipelines, and joblib serialization.</p>"},{"location":"notebooks/#3-03_baseline_modelipynb-logistic-regression-baseline","title":"3. 03_baseline_model.ipynb - Logistic Regression Baseline","text":"<p>Purpose: Train and evaluate baseline Logistic Regression classifier.</p> <p>Key Features:</p> <ul> <li>LogisticRegression with multinomial objective</li> <li>Dual confusion matrices (raw counts + normalized percentages)</li> <li>Per-class performance bar charts</li> <li>Model persistence for CLI/UI</li> </ul> <p>Performance: 92-95% overall accuracy, strong on malware/data_exfiltration, weaker on web_attack/access_abuse confusion.</p>"},{"location":"notebooks/#4-04_model_interpretabilityipynb-feature-importance-analysis","title":"4. 04_model_interpretability.ipynb - Feature Importance Analysis","text":"<p>Purpose: Explain model decisions through coefficient analysis.</p> <p>Key Features:</p> <ul> <li>Top predictive terms per class (coefficient heatmaps)</li> <li>Weight distribution histograms</li> <li>Domain knowledge validation (sensible vs spurious correlations)</li> </ul> <p>Learning Outcomes: Understand linear model coefficients as feature importance, validate model reasoning.</p>"},{"location":"notebooks/#5-05_inference_and_cliipynb-prediction-workflow-cli-testing","title":"5. 05_inference_and_cli.ipynb - Prediction Workflow &amp; CLI Testing","text":"<p>Purpose: Demonstrate inference and validate CLI consistency.</p> <p>Key Features:</p> <ul> <li>Notebook inference with probability outputs</li> <li>CLI testing (<code>python -m triage.cli</code>)</li> <li>Interactive session with Ctrl+C handling</li> <li>Prediction comparison (notebook vs CLI)</li> </ul> <p>Learning Outcomes: Master joblib loading, predict_proba() output, command-line packaging.</p>"},{"location":"notebooks/#6-06_model_visualization_and_insightsipynb-performance-analysis","title":"6. 06_model_visualization_and_insights.ipynb - Performance Analysis","text":"<p>Purpose: Comprehensive visualization and results interpretation.</p> <p>Key Features:</p> <ul> <li>Probability distribution histograms</li> <li>Per-class metrics grouped bar charts</li> <li>Confidence calibration analysis</li> <li>Comprehensive markdown: Overall performance, confusion patterns, feature validation, deployment readiness, future enhancements</li> </ul> <p>Learning Outcomes: Interpret performance in business context, assess calibration, identify improvement opportunities.</p>"},{"location":"notebooks/#7-07_scenario_based_evaluationipynb-edge-case-testing","title":"7. 07_scenario_based_evaluation.ipynb - Edge Case Testing","text":"<p>Purpose: Validate model on curated test scenarios.</p> <p>Key Features:</p> <ul> <li>Handcrafted incident scenarios (clear-cut, ambiguous, adversarial, novel phrasing)</li> <li>Expected vs predicted comparison</li> <li>Failure analysis with confidence scoring</li> </ul> <p>Learning Outcomes: Understand model limitations, vocabulary gaps, misleading confidence.</p>"},{"location":"notebooks/#8-08_model_comparisonipynb-multi-model-benchmarking","title":"8. 08_model_comparison.ipynb - Multi-Model Benchmarking","text":"<p>Purpose: Compare Logistic Regression, Linear SVM, and Random Forest.</p> <p>Key Features:</p> <ul> <li>Side-by-side performance metrics</li> <li>Enhanced confusion matrices (dual plots + comparative heatmaps)</li> <li>Model agreement analysis</li> <li>Training time comparison</li> <li>Section 8.6 comprehensive analysis: Performance ranking, per-class winners, deployment recommendation</li> </ul> <p>Learning Outcomes: Algorithm selection tradeoffs, when accuracy gains don't justify complexity, ensemble opportunities.</p>"},{"location":"notebooks/#9-09_operational_decision_supportipynb-uncertainty-thresholds","title":"9. 09_operational_decision_support.ipynb - Uncertainty &amp; Thresholds","text":"<p>Purpose: Operationalize model with uncertainty quantification.</p> <p>Key Features:</p> <ul> <li>Uncertainty metrics (confidence, entropy, top-2 gap)</li> <li>ROC/PR curves per class</li> <li>Confidence calibration diagrams</li> <li>SOC analyst escalation framework (auto-triage &gt;0.9, review 0.7-0.9, escalate &lt;0.7)</li> </ul> <p>Learning Outcomes: Quantify prediction uncertainty, set confidence thresholds, design human-in-the-loop workflows.</p>"},{"location":"notebooks/#10-10_hybrid_modelipynb-text-metadata-feature-fusion-new","title":"10. 10_hybrid_model.ipynb - Text + Metadata Feature Fusion (NEW)","text":"<p>Purpose: Combine TF-IDF with structured metadata.</p> <p>Key Features:</p> <ul> <li>Enhanced preprocessor with detailed text summaries</li> <li>Feature engineering: TF-IDF (3000) + structured (severity, log_source, protocol, ports, is_true_positive)</li> <li>ColumnTransformer for heterogeneous features</li> <li>4-model comparison (TF-IDF only, metadata only, hybrid LogReg, hybrid RF)</li> <li>Performance decomposition and interpretation</li> </ul> <p>Learning Outcomes: Master ColumnTransformer, understand feature fusion tradeoffs, design multi-input pipelines.</p>"},{"location":"notebooks/#getting-started","title":"Getting Started","text":"<pre><code># Install dependencies\npip install -e \".[dev]\"\npip install jupyterlab\n\n# Launch Jupyter Lab\njupyter lab notebooks/\n</code></pre>"},{"location":"notebooks/#recommended-reading-order","title":"Recommended Reading Order","text":"<p>New users: 00 \u2192 01 \u2192 02 \u2192 03 \u2192 05 \u2192 06-09 \u2192 10 SOC analysts: 00 \u2192 01 \u2192 05 \u2192 09 ML engineers: 00 \u2192 03 \u2192 04 \u2192 08 \u2192 10 Contributors: 00 \u2192 01 \u2192 02 \u2192 03</p>"},{"location":"notebooks/#notebook-enhancements","title":"Notebook Enhancements","text":"<p>\u2705 Professional Visualizations: Custom colormaps, dual confusion matrices, grouped bar charts \u2705 Comprehensive Markdown: Results interpretation, deployment readiness, future enhancements \u2705 Bug Fixes: Notebook 01 alignment, 05 duplicate output/Ctrl+C, 09 histogram 'kde' parameter, 10 enhanced preprocessor outputs \u2705 Code Quality: Consistent styling, reproducible seeds (random_state=42), modular cells</p>"},{"location":"notebooks/#common-issues-solutions","title":"Common Issues &amp; Solutions","text":"<p>\"Model file not found\": Run notebooks 02-03 to generate artifacts \"Dataset not found\": Generate with <code>./launch_generator.sh</code> or download pre-generated Memory issues: Load subset with <code>pd.read_csv(..., nrows=10000)</code> Plots not displaying: Add <code>%matplotlib inline</code> to first cell Kernel crashes: Reduce <code>max_features</code> in TF-IDF vectorizer</p>"},{"location":"notebooks/#best-practices","title":"Best Practices","text":"<ol> <li>Run notebooks in order first time (artifact dependencies)</li> <li>Clear outputs before committing (<code>jupyter nbconvert --clear-output</code>)</li> <li>Set random seeds for reproducibility</li> <li>Regenerate artifacts if dataset changes</li> <li>Test on subset before full 100K dataset</li> </ol>"},{"location":"notebooks/#additional-resources","title":"Additional Resources","text":"<ul> <li>Dataset Details: Data &amp; Generator Guide</li> <li>Production Scripts: Production Generation Guide</li> </ul>"},{"location":"production-generation/","title":"Production Dataset Generation","text":"<p>This guide covers production-scale dataset generation using LLM-enhanced scripts for creating realistic, large-scale cybersecurity incident datasets.</p>"},{"location":"production-generation/#overview","title":"Overview","text":"<p>The production generation system consists of two key bash scripts that orchestrate the Python generator with advanced features:</p> <ol> <li><code>launch_generator.sh</code> - Launches dataset generation with checkpointing, LLM integration, and background processing</li> <li><code>monitor_generation.sh</code> - Real-time monitoring dashboard with GPU metrics, throughput analysis, and performance tracking</li> </ol> <p>These scripts are designed for long-running, unattended dataset generation (hours to days) with automatic resume capability.</p>"},{"location":"production-generation/#quick-start","title":"Quick Start","text":""},{"location":"production-generation/#basic-generation-100k-events-default-settings","title":"Basic Generation (100K events, default settings)","text":"<pre><code>cd generator\n./launch_generator.sh\n</code></pre>"},{"location":"production-generation/#custom-dataset-size-and-name","title":"Custom Dataset Size and Name","text":"<pre><code># Generate 50,000 events with custom name\n./launch_generator.sh 50000 my_custom_dataset\n\n# Fresh start (delete existing files)\n./launch_generator.sh 100000 cyber_incidents_simulated --fresh\n</code></pre>"},{"location":"production-generation/#monitor-progress","title":"Monitor Progress","text":"<pre><code># Single snapshot\n./monitor_generation.sh\n\n# Auto-refresh every 30 seconds\n./monitor_generation.sh --watch\n\n# Auto-refresh every 10 seconds\n./monitor_generation.sh --watch 10\n\n# Monitor custom dataset\n./monitor_generation.sh my_custom_dataset --watch\n</code></pre>"},{"location":"production-generation/#launch_generatorsh","title":"launch_generator.sh","text":""},{"location":"production-generation/#purpose","title":"Purpose","text":"<p>Launches the Python dataset generator as a background process with:</p> <ul> <li>LLM-enhanced generation: Optional Llama-2-13B-Chat for realistic narrative rewrites</li> <li>Checkpoint/resume: Automatic progress saving and resume capability</li> <li>Background processing: Runs via <code>nohup</code> for SSH-safe operation</li> <li>Error recovery: Handles interruptions gracefully</li> </ul>"},{"location":"production-generation/#usage","title":"Usage","text":"<pre><code>./launch_generator.sh [events] [dataset_name] [--fresh]\n</code></pre>"},{"location":"production-generation/#parameters","title":"Parameters","text":"Parameter Description Default <code>events</code> Number of incidents to generate 100000 <code>dataset_name</code> Output dataset name (no <code>.csv</code> extension) cyber_incidents_simulated <code>--fresh</code> Delete existing files and start fresh Resume from checkpoint"},{"location":"production-generation/#examples","title":"Examples","text":"<pre><code># Default: 100K events, resume from checkpoint\n./launch_generator.sh\n\n# 50K events with custom name\n./launch_generator.sh 50000 training_data\n\n# 200K events, fresh start (delete old files)\n./launch_generator.sh 200000 large_dataset --fresh\n\n# Resume existing generation\n./launch_generator.sh 100000 cyber_incidents_simulated\n</code></pre>"},{"location":"production-generation/#llm-configuration","title":"LLM Configuration","text":"<p>The script automatically configures the LLM with production-optimized settings:</p> <pre><code>export NLP_TRIAGE_LLM_GENERATOR=1             # Enable LLM generation\nexport NLP_TRIAGE_LLM_REWRITE_PROB=0.01       # 1% of events get LLM enhancement\nexport NLP_TRIAGE_LLM_TEMPERATURE=0.2         # Focused, deterministic output\nexport NLP_TRIAGE_LLM_MAX_RETRIES=3           # Retry failed LLM calls\nexport NLP_TRIAGE_LLM_DEBUG=0                 # Disable verbose logging\nexport NLP_TRIAGE_LLM_BACKEND=\"models/llama-2-13b-chat.Q5_K_S.gguf\"\n</code></pre> <p>Model: Llama-2-13B-Chat (7.5GB GGUF quantized)</p> <ul> <li>Requires: ~10GB RAM (M1/M2 Mac with Metal acceleration)</li> <li>Performance: ~10-20 tokens/sec on Apple Silicon</li> </ul>"},{"location":"production-generation/#output-files","title":"Output Files","text":"File Description <code>data/{dataset_name}.csv</code> Main dataset (100K rows ~99MB) <code>data/{dataset_name}.log</code> Detailed generation log with timestamps <code>data/{dataset_name}_checkpoint.json</code> Progress state for resume capability <code>data/{dataset_name}_llm_report.json</code> LLM usage statistics and metrics <code>data/nohup_output.log</code> Raw stdout/stderr from background process"},{"location":"production-generation/#interactive-resume-handling","title":"Interactive Resume Handling","text":"<p>If existing files are detected without <code>--fresh</code>, you'll be prompted:</p> <pre><code>\u26a0\ufe0f  WARNING: Existing files detected:\n   - data/cyber_incidents_simulated.csv\n   - data/cyber_incidents_simulated_checkpoint.json\n\nChoose an option:\n   r) Resume from checkpoint (default)\n   f) Fresh start (delete existing files)\n   q) Quit\nChoice (r/f/q):\n</code></pre>"},{"location":"production-generation/#process-management","title":"Process Management","text":"<pre><code># Check if generation is running\npgrep -f \"generate_cyber_incidents.py\"\n\n# Kill running generation\npkill -f generate_cyber_incidents\n\n# View background output\ntail -f data/nohup_output.log\n\n# View detailed logs\ntail -f data/cyber_incidents_simulated.log\n</code></pre>"},{"location":"production-generation/#monitor_generationsh","title":"monitor_generation.sh","text":""},{"location":"production-generation/#purpose_1","title":"Purpose","text":"<p>Real-time monitoring dashboard providing:</p> <ul> <li>Process status: CPU, memory, runtime metrics</li> <li>Progress tracking: Events completed, ETA, throughput</li> <li>GPU acceleration: Metal/Apple Silicon metrics when using LLM</li> <li>Performance analysis: Throughput trends, efficiency metrics</li> <li>File status: Dataset size, log sizes</li> </ul>"},{"location":"production-generation/#usage_1","title":"Usage","text":"<pre><code>./monitor_generation.sh [dataset_name] [options]\n</code></pre>"},{"location":"production-generation/#options","title":"Options","text":"Option Description <code>dataset_name</code> Name of dataset to monitor (default: cyber_incidents_simulated) <code>--watch</code>, <code>-w [interval]</code> Auto-refresh mode (default 30s interval) <code>--simple</code>, <code>-s</code> ASCII symbols, no colors (for problematic terminals) <code>--simple-color</code> ASCII symbols WITH colors (best for SSH/tmux) <code>--help</code>, <code>-h</code> Show help message"},{"location":"production-generation/#examples_1","title":"Examples","text":"<pre><code># Single snapshot\n./monitor_generation.sh\n\n# Auto-refresh every 30 seconds\n./monitor_generation.sh --watch\n\n# Auto-refresh every 10 seconds\n./monitor_generation.sh --watch 10\n\n# Monitor custom dataset\n./monitor_generation.sh my_dataset --watch\n\n# Simple mode for SSH/tmux\n./monitor_generation.sh --simple-color --watch\n</code></pre>"},{"location":"production-generation/#dashboard-sections","title":"Dashboard Sections","text":""},{"location":"production-generation/#1-process-status","title":"1. Process Status","text":"<ul> <li>PID: Background process identifier</li> <li>CPU Usage: Per-core and total CPU utilization</li> <li>Memory Usage: Process memory consumption vs total system RAM</li> <li>Runtime: Process uptime</li> <li>GPU Acceleration (Apple Silicon only):</li> <li>Metal GPU detection and core count</li> <li>LLM model information (Llama-2-13B-Chat)</li> <li>GPU throughput metrics (rewrites/hr, tokens/sec)</li> <li>Enhancement rate (% of events LLM-enhanced)</li> </ul>"},{"location":"production-generation/#2-progress-status","title":"2. Progress Status","text":"<ul> <li>Real-time progress: Current/Total events with percentage</li> <li>Progress bar: Visual 50-character bar with completion indicator</li> <li>Generation status: Generating/Initializing/LLM loading</li> <li>Throughput trend: Accelerating/Declining/Steady analysis</li> <li>ETA: Estimated completion time with full timestamp</li> </ul>"},{"location":"production-generation/#3-file-status","title":"3. File Status","text":"<ul> <li>Dataset file: Size in human-readable format (MB/GB) with event count</li> <li>Log file: Generation log size</li> <li>Nohup output: Background process output size</li> </ul>"},{"location":"production-generation/#4-recent-activity","title":"4. Recent Activity","text":"<ul> <li>Last 5 log entries: Tail of detailed log</li> <li>Chunk analysis:</li> <li>Average chunk interval (time between chunks)</li> <li>Last chunk interval (most recent timing)</li> <li>Total chunks completed</li> </ul>"},{"location":"production-generation/#5-performance-metrics","title":"5. Performance Metrics","text":"<ul> <li>Generation runtime: Total time since start</li> <li>Time per event: Average seconds per incident</li> <li>Events/second: Throughput rate</li> <li>Progress velocity: Percentage completion per hour</li> <li>Estimated time remaining: Hours/minutes until completion</li> <li>Resource efficiency: Events per CPU%, Events per GB RAM</li> </ul>"},{"location":"production-generation/#sample-output","title":"Sample Output","text":"<pre><code>\ud83d\udee0\ufe0f  CYBERSECURITY DATASET GENERATION MONITOR\n==============================================\nDataset: cyber_incidents_simulated\nStarted: Fri Nov 22 08:15:30 CST 2024\nETA: Fri Nov 22 14:32:15 CST 2024\n\n\ud83d\udcc8  PROCESS STATUS\n-----------------\n\u2705  Generation process RUNNING (PID: 12345)\n   CPU Usage: 125.3% (7.8% per core, 16 cores total)\n   Memory Usage: 8.2% (2.1GB of 32.0GB total)\n   Runtime: 2:15:42 (process uptime)\n   \ud83c\udfae GPU Acceleration: Metal (Apple M2 Max - 38 cores)\n      LLM Model: llama-2-13b-chat.Q5_K_S.gguf\n      LLM Activity: 845/850 rewrites processed\n      Enhancement: 0.8% of events (99.4% success rate)\n      GPU Throughput: 375.2/hr (9.6s avg per rewrite)\n      Inference Speed: ~18.5 tokens/sec\n   Efficiency: 1,234 events/CPU%, 15,600 events/GB\n\n\ud83d\udcc8  PROGRESS STATUS\n------------------\n\ud83d\ude80 Generation active: 25000/100000 (25.0%)\n   [\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2591\u2591\u2591\u2591\u2591\u2591\u2591\u2591\u2591\u2591\u2591\u2591\u2591\u2591\u2591\u2591\u2591\u2591\u2591\u2591\u2591\u2591\u2591\u2591\u2591\u2591\u2591\u2591] 25.0% Complete\n   Status: Generating events...\n   \ud83d\udcc8 Throughput: Steady\n\n\ud83d\udcc1  FILE STATUS\n--------------\n\u2705 Dataset: 24.5M (25000 events)\n\u2705 Log file: 1.2M\n\u2705 Nohup output: 45K\n\n\ud83d\udcdd  RECENT ACTIVITY\n------------------\nLast 5 log entries:\n   2024-11-22 10:30:15 - Writing chunk 250\n   2024-11-22 10:30:12 - Generating events: 25000/100000\n   2024-11-22 10:29:58 - Writing chunk 249\n   ...\n\n\ud83d\udce6 Chunk Analysis:\n   Average chunk interval: 5m 23s\n   Last chunk interval: 5m 15s\n   Total chunks completed: 250\n\n\u26a1 PERFORMANCE\n-------------\n   Generation runtime: 2h 15m 42s\n   Started: 2024-11-22 08:15:30\n   Progress velocity: 11.1%/hour\n   Time per event: 0.3s\n   Estimated time remaining: 6h 15m\n   Events/second: 3.088 (avg)\n\n\ud83d\udee0\ufe0f  QUICK ACTIONS\n----------------\nMonitor real-time: tail -f ../data/cyber_incidents_simulated.log\nCheck progress:    cat ../data/cyber_incidents_simulated_checkpoint.json | jq\nKill process:      pkill -f generate_cyber_incidents\nView nohup output: tail -f ../data/nohup_output.log\n\n\ud83d\ude80 STATUS: Generation active (25.0% complete)\n</code></pre>"},{"location":"production-generation/#gpu-metrics-apple-silicon","title":"GPU Metrics (Apple Silicon)","text":"<p>When LLM enhancement is enabled on Apple Silicon Macs, the monitor shows:</p> <ul> <li>GPU Model: e.g., \"Apple M2 Max - 38 cores\"</li> <li>LLM Model: Loaded model file (llama-2-13b-chat.Q5_K_S.gguf)</li> <li>Enhancement Rate: Percentage of events LLM-enhanced</li> <li>GPU Throughput: Rewrites per hour, average time per rewrite</li> <li>Inference Speed: Estimated tokens/second</li> <li>Success Rate: % of successful LLM rewrites</li> </ul>"},{"location":"production-generation/#performance-trending","title":"Performance Trending","text":"<p>The monitor calculates throughput trends by sampling recent progress:</p> <ul> <li>Accelerating: Throughput increasing (shows +X%)</li> <li>Steady: Consistent throughput</li> <li>Declining: Throughput decreasing (shows -X%)</li> </ul>"},{"location":"production-generation/#checkpointing-system","title":"Checkpointing System","text":""},{"location":"production-generation/#how-it-works","title":"How It Works","text":"<p>The generator saves progress every 100 events (configurable via <code>--chunk-size</code>):</p> <pre><code>{\n  \"last_completed_event\": 25000,\n  \"total_events\": 100000,\n  \"chunks_written\": 250,\n  \"timestamp\": \"2024-11-22T10:30:15\",\n  \"status\": \"running\",\n  \"generation_start_time\": \"2024-11-22T08:15:30\"\n}\n</code></pre>"},{"location":"production-generation/#resume-behavior","title":"Resume Behavior","text":"<p>When you restart the generator:</p> <ol> <li>Checks for existing checkpoint file</li> <li>Reads <code>last_completed_event</code></li> <li>Continues from event 25001</li> <li>Appends to existing CSV file</li> </ol> <p>No data is duplicated or lost - the CSV header is NOT re-written on resume.</p>"},{"location":"production-generation/#manual-checkpoint-inspection","title":"Manual Checkpoint Inspection","text":"<pre><code># View checkpoint status\ncat data/cyber_incidents_simulated_checkpoint.json | jq\n\n# Check progress percentage\njq -r '\"\\(.last_completed_event)/\\(.total_events) = \\((.last_completed_event / .total_events * 100) | tostring + \"%\")\"' \\\n  data/cyber_incidents_simulated_checkpoint.json\n</code></pre>"},{"location":"production-generation/#llm-enhanced-generation","title":"LLM-Enhanced Generation","text":""},{"location":"production-generation/#what-gets-enhanced","title":"What Gets Enhanced?","text":"<p>With <code>NLP_TRIAGE_LLM_REWRITE_PROB=0.01</code> (default), approximately 1% of events receive LLM enhancement:</p> <ul> <li>Narrative rewriting: More realistic phrasing and SOC language</li> <li>Technical detail addition: Specific IPs, file hashes, timestamps</li> <li>Contextual enrichment: Background information, user quotes</li> <li>Complexity variation: Mix of terse/verbose descriptions</li> </ul>"},{"location":"production-generation/#llm-report","title":"LLM Report","text":"<p>After generation, check <code>data/{dataset_name}_llm_report.json</code>:</p> <pre><code>{\n  \"rewrites_attempted\": 1050,\n  \"rewrites_applied\": 1043,\n  \"rewrite_success_rate\": 0.993,\n  \"average_rewrite_time_seconds\": 9.6,\n  \"total_llm_time_seconds\": 10012.8,\n  \"model_path\": \"models/llama-2-13b-chat.Q5_K_S.gguf\",\n  \"temperature\": 0.2,\n  \"max_retries\": 3\n}\n</code></pre> <p>Metrics explanation:</p> <ul> <li>rewrites_attempted: Total LLM calls triggered (1% of 100K = ~1000)</li> <li>rewrites_applied: Successfully enhanced events</li> <li>success_rate: Percentage of successful LLM rewrites (typically 99%+)</li> <li>average_rewrite_time: Seconds per LLM call (~10s for 13B model)</li> <li>total_llm_time: Cumulative GPU inference time</li> </ul>"},{"location":"production-generation/#disabling-llm","title":"Disabling LLM","text":"<p>For faster generation without LLM enhancement:</p> <pre><code># Edit launch_generator.sh and comment out:\n# export NLP_TRIAGE_LLM_GENERATOR=1\n\n# Or manually run without LLM:\npython generate_cyber_incidents.py --n-events 100000 --outfile ../data/dataset.csv\n</code></pre> <p>Speed comparison:</p> <ul> <li>With LLM (1% rewrite): ~3-5 events/sec (~6-9 hours for 100K)</li> <li>Without LLM: ~50-100 events/sec (~20-30 minutes for 100K)</li> </ul>"},{"location":"production-generation/#advanced-usage","title":"Advanced Usage","text":""},{"location":"production-generation/#custom-python-call-manual-control","title":"Custom Python Call (Manual Control)","text":"<pre><code>cd generator\n\n# Direct Python call with all parameters\npython generate_cyber_incidents.py \\\n  --n-events 50000 \\\n  --outfile ../data/my_dataset.csv \\\n  --start-date 2024-01-01 \\\n  --end-date 2024-12-31 \\\n  --chunk-size 100 \\\n  --log-file ../data/my_dataset.log \\\n  --checkpoint-file ../data/my_dataset_checkpoint.json \\\n  --use-llm \\\n  --rewrite-report ../data/my_dataset_llm_report.json\n</code></pre>"},{"location":"production-generation/#environment-variable-customization","title":"Environment Variable Customization","text":"<pre><code># Higher LLM rewrite rate (10% of events)\nexport NLP_TRIAGE_LLM_REWRITE_PROB=0.10\n\n# More creative LLM output\nexport NLP_TRIAGE_LLM_TEMPERATURE=0.7\n\n# Verbose LLM debugging\nexport NLP_TRIAGE_LLM_DEBUG=1\n\n# Custom model path\nexport NLP_TRIAGE_LLM_BACKEND=\"/path/to/custom-model.gguf\"\n\n# Then launch\n./launch_generator.sh\n</code></pre>"},{"location":"production-generation/#multiple-concurrent-generations","title":"Multiple Concurrent Generations","text":"<p>You can run multiple generators simultaneously with different dataset names:</p> <pre><code># Terminal 1: Generate training dataset\n./launch_generator.sh 100000 training_data --fresh\n\n# Terminal 2: Generate validation dataset\n./launch_generator.sh 20000 validation_data --fresh\n\n# Terminal 3: Monitor both\n./monitor_generation.sh training_data --watch &amp;\n./monitor_generation.sh validation_data --watch\n</code></pre> <p>Note: Each generator will compete for CPU/GPU resources. On Apple Silicon, running 2 LLM-enhanced generators will slow both down ~50%.</p>"},{"location":"production-generation/#troubleshooting","title":"Troubleshooting","text":""},{"location":"production-generation/#generator-wont-start","title":"Generator Won't Start","text":"<p>Error: <code>Generation already running (PID: 12345)</code></p> <p>Solution:</p> <pre><code># Kill existing process\npkill -f generate_cyber_incidents\n\n# Or use --fresh to auto-kill\n./launch_generator.sh 100000 my_dataset --fresh\n</code></pre>"},{"location":"production-generation/#llm-model-not-found","title":"LLM Model Not Found","text":"<p>Error: <code>LLM model not found: models/llama-2-13b-chat.Q5_K_S.gguf</code></p> <p>Solution:</p> <pre><code># Download the model (7.5GB)\ncd models\n# Use your preferred download method for Llama-2-13B-Chat GGUF Q5_K_S quantization\n\n# Or disable LLM in launch_generator.sh\n# Comment out: export NLP_TRIAGE_LLM_GENERATOR=1\n</code></pre>"},{"location":"production-generation/#slow-generation-speed","title":"Slow Generation Speed","text":"<p>Issue: Only 0.5 events/sec with LLM enabled</p> <p>Causes:</p> <ol> <li>High rewrite probability: Check <code>NLP_TRIAGE_LLM_REWRITE_PROB</code> (should be 0.01-0.05)</li> <li>Large model: 13B model is slower than 7B (but higher quality)</li> <li>Memory swapping: System RAM exhausted, using swap</li> <li>Other processes: GPU/CPU contention</li> </ol> <p>Solutions:</p> <pre><code># Lower rewrite probability\nexport NLP_TRIAGE_LLM_REWRITE_PROB=0.01  # 1% instead of 10%\n\n# Use smaller 7B model (faster, lower quality)\nexport NLP_TRIAGE_LLM_BACKEND=\"models/llama-2-7b-chat.Q5_K_S.gguf\"\n\n# Disable LLM entirely\n# Comment out: export NLP_TRIAGE_LLM_GENERATOR=1\n\n# Close other applications to free RAM/GPU\n</code></pre>"},{"location":"production-generation/#monitor-shows-no-active-generation","title":"Monitor Shows \"No active generation\"","text":"<p>Issue: Process is running but monitor doesn't detect it</p> <p>Cause: Process name mismatch (using custom dataset name)</p> <p>Solution:</p> <pre><code># Specify dataset name explicitly\n./monitor_generation.sh my_custom_dataset --watch\n</code></pre>"},{"location":"production-generation/#resume-not-working","title":"Resume Not Working","text":"<p>Issue: Generator starts from 0 instead of resuming</p> <p>Causes:</p> <ol> <li>Checkpoint file corrupted</li> <li>Used <code>--fresh</code> flag</li> <li>Dataset name mismatch</li> </ol> <p>Solution:</p> <pre><code># Check checkpoint exists\nls -lh data/cyber_incidents_simulated_checkpoint.json\n\n# View checkpoint contents\ncat data/cyber_incidents_simulated_checkpoint.json | jq\n\n# If corrupted, delete and start fresh\nrm data/cyber_incidents_simulated_checkpoint.json\n./launch_generator.sh 100000 cyber_incidents_simulated --fresh\n</code></pre>"},{"location":"production-generation/#performance-optimization","title":"Performance Optimization","text":""},{"location":"production-generation/#maximizing-speed-no-llm","title":"Maximizing Speed (No LLM)","text":"<pre><code># Disable LLM in launch_generator.sh\n# Comment out: export NLP_TRIAGE_LLM_GENERATOR=1\n\n# Larger chunk size (fewer disk writes)\n# Edit generate_cyber_incidents.py: --chunk-size 1000\n\n# Expected: ~50-100 events/sec (100K events in 20-30 minutes)\n</code></pre>"},{"location":"production-generation/#balancing-quality-vs-speed","title":"Balancing Quality vs Speed","text":"Configuration Speed Quality Time for 100K No LLM 50-100 evt/s Good 20-30 min LLM 1% 3-5 evt/s Excellent 6-9 hours LLM 5% 2-3 evt/s Best 10-15 hours LLM 10% 1-2 evt/s Overkill 15-24 hours <p>Recommendation: Use 1-2% LLM enhancement for production datasets - provides excellent quality without excessive generation time.</p>"},{"location":"production-generation/#resource-requirements","title":"Resource Requirements","text":"<p>Minimum:</p> <ul> <li>8GB RAM</li> <li>2-core CPU</li> <li>5GB disk space (for 100K events)</li> </ul> <p>Recommended (with LLM):</p> <ul> <li>16GB RAM (10GB for model + 6GB for system)</li> <li>4+ core CPU (Apple Silicon M1/M2 ideal)</li> <li>10GB disk space (dataset + logs + checkpoints)</li> <li>macOS with Metal support (for GPU acceleration)</li> </ul> <p>Optimal (large-scale generation):</p> <ul> <li>32GB+ RAM</li> <li>8+ core CPU</li> <li>50GB+ disk space (multiple datasets)</li> <li>Apple Silicon M1 Max/M2 Max/M3 (faster GPU)</li> </ul>"},{"location":"production-generation/#example-workflows","title":"Example Workflows","text":""},{"location":"production-generation/#quick-test-dataset-1k-events-no-llm","title":"Quick Test Dataset (1K events, no LLM)","text":"<pre><code># Edit launch_generator.sh: comment out LLM_GENERATOR\n./launch_generator.sh 1000 test_data --fresh\n# Wait ~20-30 seconds\n./monitor_generation.sh test_data\n</code></pre>"},{"location":"production-generation/#production-dataset-100k-events-1-llm","title":"Production Dataset (100K events, 1% LLM)","text":"<pre><code># Default configuration (already set in launch_generator.sh)\n./launch_generator.sh 100000 cyber_incidents_simulated --fresh\n\n# Monitor in another terminal\n./monitor_generation.sh --watch 60  # Refresh every minute\n\n# Expected completion: 6-9 hours\n# Check completion: grep \"completed successfully\" data/cyber_incidents_simulated.log\n</code></pre>"},{"location":"production-generation/#large-scale-dataset-500k-events-overnight","title":"Large-Scale Dataset (500K events, overnight)","text":"<pre><code># Launch before leaving for the day\n./launch_generator.sh 500000 large_dataset --fresh\n\n# Monitor remotely via SSH (use simple mode)\nssh your-machine\ncd /path/to/generator\n./monitor_generation.sh large_dataset --simple-color --watch\n\n# Expected completion: 30-45 hours with 1% LLM\n</code></pre>"},{"location":"production-generation/#best-practices","title":"Best Practices","text":"<ol> <li>Always use <code>--watch</code> mode when monitoring long-running generations</li> <li>Check disk space before large generations (<code>df -h</code>)</li> <li>Use checkpoints - never start fresh unless necessary</li> <li>Review LLM report after completion to validate enhancement success rate</li> <li>Test with small datasets before committing to 100K+ event generations</li> <li>Monitor GPU temperature on long runs (use Activity Monitor on macOS)</li> <li>Use <code>nohup</code>/background execution for SSH sessions</li> <li>Keep rewrite probability low (1-2%) for good quality without excessive time</li> <li>Archive completed datasets with LLM reports for reproducibility</li> <li>Document your generation settings in dataset metadata files</li> </ol>"},{"location":"production-generation/#next-steps","title":"Next Steps","text":"<p>After generating your dataset:</p> <ol> <li>Validate dataset quality: Check <code>notebooks/01_explore_dataset.ipynb</code></li> <li>Train models: Follow notebooks 02-03 for feature engineering and baseline model</li> <li>Customize generator: See <code>data-and-generator.md</code> for vocabulary/template modifications</li> <li>Share your dataset: Consider contributing anonymized versions back to the project</li> </ol> <p>For dataset structure and customization details, see Data &amp; Generator Guide.</p>"},{"location":"quickstart/","title":"Quick Start Guide","text":"<p>Get AlertSage running in 5 minutes!</p>"},{"location":"quickstart/#prerequisites","title":"Prerequisites","text":"<ul> <li>Python 3.11+ (check with <code>python --version</code>)</li> <li>Git (check with <code>git --version</code>)</li> <li>~500 MB free disk space for models and dataset</li> </ul>"},{"location":"quickstart/#installation","title":"Installation","text":""},{"location":"quickstart/#1-clone-the-repository","title":"1. Clone the Repository","text":"<pre><code>git clone https://github.com/texasbe2trill/AlertSage.git\ncd AlertSage\n</code></pre>"},{"location":"quickstart/#2-create-virtual-environment","title":"2. Create Virtual Environment","text":"<pre><code># macOS/Linux\npython3.11 -m venv .venv\nsource .venv/bin/activate\n\n# Windows\npython -m venv .venv\n.venv\\Scripts\\activate\n</code></pre>"},{"location":"quickstart/#3-install-package","title":"3. Install Package","text":"<pre><code>pip install -e \".[dev]\"\n</code></pre> <p>This installs AlertSage in editable mode with all dependencies.</p>"},{"location":"quickstart/#verify-installation","title":"Verify Installation","text":""},{"location":"quickstart/#run-tests","title":"Run Tests","text":"<pre><code>pytest\n</code></pre> <p>You should see all 9 tests pass. The first run will automatically download the model artifacts (~10 MB).</p>"},{"location":"quickstart/#test-cli","title":"Test CLI","text":"<pre><code>nlp-triage \"User reported suspicious email with attachment\"\n</code></pre> <p>You should see a formatted output with classification results.</p>"},{"location":"quickstart/#next-steps","title":"Next Steps","text":""},{"location":"quickstart/#try-the-streamlit-ui","title":"Try the Streamlit UI","text":"<pre><code>streamlit run ui_premium.py\n</code></pre> <p>Your browser will open to <code>http://localhost:8501</code> with an interactive dashboard.</p>"},{"location":"quickstart/#explore-notebooks","title":"Explore Notebooks","text":"<pre><code>jupyter notebook notebooks/\n</code></pre> <p>Start with <code>01_explore_dataset.ipynb</code> to see the full workflow.</p>"},{"location":"quickstart/#generate-custom-dataset","title":"Generate Custom Dataset","text":"<pre><code># Generate 1000 incidents (quick test)\npython generator/generate_cyber_incidents.py --n-events 1000\n</code></pre>"},{"location":"quickstart/#common-issues","title":"Common Issues","text":""},{"location":"quickstart/#module-triage-not-found","title":"\"Module 'triage' not found\"","text":"<p>Make sure you ran <code>pip install -e \".[dev]\"</code> and your virtual environment is activated.</p>"},{"location":"quickstart/#no-such-file-cyber_incidents_simulatedcsv","title":"\"No such file: cyber_incidents_simulated.csv\"","text":"<p>The dataset auto-downloads when you run tests or notebooks. Manually download if needed:</p> <pre><code>pytest tests/test_model_artifacts.py\n</code></pre>"},{"location":"quickstart/#python-311-not-found","title":"\"Python 3.11 not found\"","text":"<p>Install Python 3.11+ from python.org or use a version manager like <code>pyenv</code>.</p>"},{"location":"quickstart/#port-8501-already-in-use-streamlit","title":"Port 8501 already in use (Streamlit)","text":"<pre><code>streamlit run ui_premium.py --server.port 8502\n</code></pre>"},{"location":"quickstart/#quick-command-reference","title":"Quick Command Reference","text":"<pre><code># CLI with threshold adjustment\nnlp-triage --threshold 0.7 \"Website experiencing slowdowns\"\n\n# JSON output for scripting\nnlp-triage --json \"Multiple failed login attempts\"\n\n# LLM second opinion (requires LLM model)\nnlp-triage --llm-second-opinion \"Server encrypting files\"\n\n# Run all tests\npytest -v\n\n# Check code coverage\npytest --cov=src/triage --cov-report=term-missing\n\n# Preview documentation\nmkdocs serve\n\n## Set up a local LLM (one-time)\n\nLLM features require a local GGUF model and `llama-cpp-python`:\n\n```bash\n# Create a models folder\nmkdir -p models\n\n# macOS (Metal GPU):\nCMAKE_ARGS=\"-DLLAMA_METAL=on\" pip install llama-cpp-python\n\n# Download a model (choose one)\nhuggingface-cli download TheBloke/Llama-3.1-8B-Instruct-GGUF \\\n    Llama-3.1-8B-Instruct-Q6_K.gguf --local-dir models\n\n# Or smaller alternatives:\nhuggingface-cli download TheBloke/Mistral-7B-Instruct-v0.2-GGUF \\\n    mistral-7b-instruct-v0.2.Q6_K.gguf --local-dir models\nhuggingface-cli download TinyLlama/TinyLlama-1.1B-Chat-v1.0-GGUF \\\n    TinyLlama-1.1B-Chat-v1.0.Q6_K.gguf --local-dir models\n\n# Point the app to your model\nexport TRIAGE_LLM_MODEL=\"$(pwd)/models/Llama-3.1-8B-Instruct-Q6_K.gguf\"\n\n# Test second opinion\nnlp-triage --llm-second-opinion \"Suspicious activity detected\"\n</code></pre> <p>Tip: Some models require Hugging Face login and license acceptance. ```</p>"},{"location":"quickstart/#documentation","title":"Documentation","text":"<ul> <li>Full Documentation: https://texasbe2trill.github.io/AlertSage/</li> <li>CLI Guide: docs/cli.md</li> <li>UI Guide: docs/ui-guide.md</li> <li>Development: docs/development.md</li> </ul>"},{"location":"quickstart/#getting-help","title":"Getting Help","text":"<ul> <li>Issues: GitHub Issues</li> <li>Discussions: GitHub Discussions</li> <li>Contributing: Contributing</li> </ul>"},{"location":"quickstart/#whats-next","title":"What's Next?","text":"<ol> <li>\u2705 Read the Overview</li> <li>\u2705 Try different CLI options and thresholds</li> <li>\u2705 Explore the Streamlit UI features</li> <li>\u2705 Walk through the Jupyter notebooks</li> <li>\u2705 Generate your own synthetic dataset</li> <li>\u2705 Read the documentation site</li> </ol> <p>Happy triaging! \ud83d\udee1\ufe0f</p>"},{"location":"release-notes/","title":"\ud83d\ude80 NLP-Driven Incident Triage \u2014 v0.2.0 Release Notes","text":"<p>This release delivers a major leap forward in realism, robustness, and usability. With enriched MITRE ATT&amp;CK\u00ae narratives, an upgraded CLI, batch processing, improved documentation, and enhanced testing, the project now behaves much closer to a lightweight NLP SOC analyst assistant.</p>"},{"location":"release-notes/#major-enhancements","title":"\ud83d\udd25 Major Enhancements","text":""},{"location":"release-notes/#mitre-attck-narrative-enrichment","title":"\ud83e\udde0 MITRE ATT&amp;CK\u00ae Narrative Enrichment","text":"<ul> <li>Incident generator now embeds realistic MITRE techniques across all event types:</li> <li>Phishing \u2192 T1566 (various subtypes)</li> <li>Malware \u2192 T1486, T1059 (PowerShell), etc.</li> <li>Access Abuse \u2192 T1078, T1110</li> <li>Web Attack \u2192 T1190, T1110</li> <li>Policy Violations \u2192 mapped where relevant</li> <li>Added <code>mitre_clause</code> generation per event.</li> <li>Documentation updated with required MITRE license attribution.</li> </ul>"},{"location":"release-notes/#cli-upgrades","title":"\ud83d\udcbb CLI Upgrades","text":""},{"location":"release-notes/#rich-ui-banner","title":"\u2728 Rich UI &amp; Banner","text":"<ul> <li>New ASCII NLPTriage banner on start.</li> <li>Colorized output, aligned columns, and better readability.</li> <li>Uses <code>rich</code> for tables, highlighting, and labeling.</li> </ul>"},{"location":"release-notes/#difficulty-modes-uncertainty-handling","title":"\ud83e\udd16 Difficulty Modes (Uncertainty Handling)","text":"<p>New flag: <pre><code>--difficulty {default, soc-medium, soc-hard}\n</code></pre> - Adjusts the strictness for marking predictions as <code>uncertain</code>. - <code>soc-hard</code> simulates cautious SOC analyst behavior.</p>"},{"location":"release-notes/#bulk-mode-new","title":"\ud83d\udcc2 Bulk Mode (New!)","text":"<p>New flags: <pre><code>--input-file incidents.txt\n--output-file results.jsonl\n</code></pre> - Supports batch-classifying hundreds of incidents. - Writes results as JSONL. - Includes an automated summary:   - event-type distribution   - uncertainty rate   - MITRE technique counts (from generator)   - suggested analyst review priorities</p>"},{"location":"release-notes/#prediction-enhancements","title":"\ud83c\udfaf Prediction Enhancements","text":"<ul> <li>Cleaner uncertainty threshold logic.</li> <li>Better sorting of probabilities.</li> <li>Improved preprocessing alignment between training and inference.</li> </ul>"},{"location":"release-notes/#data-modeling-improvements","title":"\ud83e\uddf1 Data &amp; Modeling Improvements","text":"<ul> <li>More realistic SOC narratives with ATT&amp;CK technique references.</li> <li>Expanded variation across event types.</li> <li>Added ambiguous real-world-like descriptions for robustness.</li> <li>Updated dataset to align with generator improvements.</li> </ul>"},{"location":"release-notes/#documentation-website-mkdocs","title":"\ud83d\udcd8 Documentation &amp; Website (MkDocs)","text":"<ul> <li>All docs updated to reflect new CLI, features, and MITRE attribution.</li> <li>New or updated pages:</li> <li>CLI Usage</li> <li>Modeling &amp; Evaluation</li> <li>Getting Started</li> <li>Limitations + MITRE License</li> <li>Realistic Model Behavior</li> </ul>"},{"location":"release-notes/#tests-ci","title":"\ud83e\uddea Tests &amp; CI","text":"<ul> <li>Expanded pytest suite:</li> <li>prediction structure tests</li> <li>artifact loading tests</li> <li>uncertainty logic tests</li> <li>CLI helper tests</li> <li>Fixed issues with test imports and artifact loading.</li> <li>GitHub CI workflow updated to validate on PRs.</li> </ul>"},{"location":"release-notes/#packaging-structure","title":"\ud83d\udce6 Packaging &amp; Structure","text":"<ul> <li>Project supports:</li> <li><code>pip install -e .</code></li> <li><code>nlp-triage</code> console entry point</li> <li>Improved <code>pyproject.toml</code>, <code>README.md</code>, and MkDocs structure.</li> </ul>"},{"location":"release-notes/#bug-fixes","title":"\ud83d\udee0\ufe0f Bug Fixes","text":"<ul> <li>Fixed issues related to path imports in CLI.</li> <li>Resolved LFS model load errors.</li> <li>Fixed probability length assumptions in tests.</li> <li>Corrected documentation sync issues.</li> </ul>"},{"location":"release-notes/#summary","title":"\ud83c\udfc1 Summary","text":"<p>v0.2.0 transforms the project from a baseline demo into a far more realistic SOC triage assistant. With MITRE integration, batch mode, enhanced CLI, and polished documentation, the project is now ready for broader use, portfolio presentation, and future extensions.</p>"},{"location":"release-notes/#upgrade-instructions","title":"\ud83c\udff7\ufe0f Upgrade Instructions","text":"<p>To install or upgrade locally:</p> <pre><code>pip install -e .\n</code></pre> <p>If you're using editable mode and updated the CLI, reinstall:</p> <pre><code>pip install -e . --force-reinstall\n</code></pre>"},{"location":"release-notes/#mitre-attck-notice","title":"\ud83d\udcce MITRE ATT&amp;CK\u00ae Notice","text":"<p>This project includes derived technique names and references from the MITRE ATT&amp;CK\u00ae framework. ATT&amp;CK\u00ae is licensed under CC BY-NC-SA 4.0. See: https://attack.mitre.org/resources/terms-of-use/</p>"},{"location":"testing/","title":"Testing Guide","text":""},{"location":"testing/#test-structure","title":"Test Structure","text":"<p>Tests are organized in the <code>tests/</code> directory:</p> <pre><code>tests/\n\u251c\u2500\u2500 test_cli.py          # CLI functionality tests\n\u251c\u2500\u2500 test_model.py        # Model loading and inference\n\u251c\u2500\u2500 test_preprocess.py   # Text preprocessing\n\u2514\u2500\u2500 conftest.py          # Shared fixtures\n</code></pre>"},{"location":"testing/#running-tests","title":"Running Tests","text":""},{"location":"testing/#all-tests","title":"All Tests","text":"<pre><code>pytest tests/ -v\n</code></pre>"},{"location":"testing/#specific-test-file","title":"Specific Test File","text":"<pre><code>pytest tests/test_cli.py -v\n</code></pre>"},{"location":"testing/#specific-test-function","title":"Specific Test Function","text":"<pre><code>pytest tests/test_cli.py::test_basic_classification -v\n</code></pre>"},{"location":"testing/#with-coverage","title":"With Coverage","text":"<pre><code>pytest tests/ --cov=src/triage --cov-report=html\n</code></pre>"},{"location":"testing/#writing-tests","title":"Writing Tests","text":""},{"location":"testing/#example-test","title":"Example Test","text":"<pre><code>import pytest\nfrom triage.preprocess import clean_description\n\ndef test_clean_description():\n    dirty = \"URGENT!!! Multiple LOGIN failures!!!\"\n    clean = clean_description(dirty)\n    assert clean == \"urgent multiple login failures\"\n    assert \"!!!\" not in clean\n</code></pre>"},{"location":"testing/#using-fixtures","title":"Using Fixtures","text":"<pre><code>@pytest.fixture\ndef sample_incident():\n    return \"User reported suspicious email with attachment\"\n\ndef test_classification(sample_incident):\n    result = classify_incident(sample_incident)\n    assert result[\"label\"] in [\"phishing\", \"malware\", \"uncertain\"]\n</code></pre>"},{"location":"testing/#test-categories","title":"Test Categories","text":""},{"location":"testing/#unit-tests","title":"Unit Tests","text":"<ul> <li>Individual function testing</li> <li>No external dependencies</li> <li>Fast execution</li> </ul>"},{"location":"testing/#integration-tests","title":"Integration Tests","text":"<ul> <li>Multiple component interaction</li> <li>Model loading and inference</li> <li>CLI end-to-end workflows</li> </ul>"},{"location":"testing/#dataset-tests","title":"Dataset Tests","text":"<ul> <li>Automatic dataset download</li> <li>Checkpoint loading</li> <li>CSV validation</li> </ul>"},{"location":"testing/#continuous-integration","title":"Continuous Integration","text":"<p>Tests run automatically on:</p> <ul> <li>Pull requests to <code>main</code> or <code>dev</code></li> <li>Pushes to <code>main</code> or <code>dev</code></li> </ul> <p>See <code>.github/workflows/python-tests.yml</code> for configuration.</p> <p>See Development Guide for more development workflows.</p>"},{"location":"ui-guide/","title":"Streamlit UI Guide","text":"<p>Launch the UI</p> <p><code>bash     streamlit run ui_premium.py</code> The UI will open in your browser at <code>http://localhost:8501</code></p>"},{"location":"ui-guide/#overview","title":"Overview","text":"<p>The NLP Cyber Incident Triage Laboratory is a comprehensive Streamlit web application providing an interactive dashboard for security incident analysis. It combines real-time classification, visual analytics, threat intelligence, and SOC automation in a modern, user-friendly interface.</p> <p></p> <p>Main interface showing the analysis dashboard</p>"},{"location":"ui-guide/#getting-started","title":"\ud83d\ude80 Getting Started","text":""},{"location":"ui-guide/#launch-the-application","title":"Launch the Application","text":"<p>From the project root directory:</p> <pre><code># Activate virtual environment\nsource .venv/bin/activate\n\n# Launch UI\nstreamlit run ui_premium.py\n</code></pre> <p>The interface will automatically open in your default browser at <code>http://localhost:8501</code>.</p>"},{"location":"ui-guide/#first-time-setup","title":"First-Time Setup","text":"<p>Before using the UI, ensure you have:</p> <ol> <li>\u2705 Installed all dependencies: <code>pip install -e .</code></li> <li>\u2705 Model files downloaded (run <code>pytest tests/test_model.py -v</code> to trigger automatic download)</li> <li>\u2705 (Optional) LLM model for second opinions: Download Llama-2-7B-Chat GGUF</li> </ol>"},{"location":"ui-guide/#interface-modes","title":"\ud83d\udccb Interface Modes","text":"<p>The UI offers three primary analysis modes accessible from the sidebar:</p>"},{"location":"ui-guide/#single-incident-analysis","title":"\ud83d\udd0d Single Incident Analysis","text":"<p>Analyze individual security incidents with comprehensive intelligence.</p> <p></p> <p>Single incident analysis with real-time classification</p> <p>Features:</p> <ul> <li>Real-time incident classification</li> <li>Confidence scoring with visual gauge</li> <li>Probability distribution charts</li> <li>MITRE ATT&amp;CK technique mapping</li> <li>Threat intelligence panel</li> <li>SOC playbook recommendations</li> <li>Risk radar visualization</li> </ul> <p>Workflow:</p> <ol> <li>Enter incident description in the text area</li> <li>Configure analysis settings in sidebar (threshold, difficulty, LLM)</li> <li>Click \"\ud83d\udd0d Analyze Incident\"</li> <li>Explore results across five analysis tabs</li> </ol>"},{"location":"ui-guide/#bulk-analysis-intelligence-center","title":"\ud83d\udcca Bulk Analysis Intelligence Center","text":"<p>Process multiple incidents from uploaded files with advanced analytics.</p> <p></p> <p>Bulk processing dashboard with aggregate metrics</p> <p>Features:</p> <ul> <li>CSV/TXT file upload support</li> <li>Batch processing with progress tracking</li> <li>Aggregate statistics and metrics</li> <li>LLM upgrade tracking (shows when AI changes classifications)</li> <li>Interactive filtering by label, confidence, uncertainty</li> <li>Export results as CSV/JSON</li> <li>Comprehensive threat intelligence briefs</li> </ul> <p>Workflow:</p> <ol> <li>Upload incidents file (CSV with <code>description</code> column or TXT with one incident per line)</li> <li>Configure batch processing settings</li> <li>Monitor real-time progress</li> <li>Review aggregate analytics</li> <li>Filter and export results</li> </ol>"},{"location":"ui-guide/#experimental-lab","title":"\ud83e\uddea Experimental Lab","text":"<p>Advanced features for research and experimentation.</p> <p> Experimental analysis tools</p> <p>Features:</p> <ul> <li>Text similarity analysis</li> <li>Incident clustering</li> <li>Model performance comparison</li> <li>Synthetic data generation</li> <li>Advanced feature extraction</li> <li>IOC lookup and threat feeds</li> </ul>"},{"location":"ui-guide/#sidebar-configuration","title":"\ud83c\udf9b\ufe0f Sidebar Configuration","text":"<p>The sidebar provides comprehensive control over analysis parameters:</p> <p></p> <p>Configuration panel with all analysis settings</p>"},{"location":"ui-guide/#analysis-settings","title":"Analysis Settings","text":"<p>Difficulty Mode</p> <ul> <li><code>default</code> - Standard thresholds (50% confidence)</li> <li><code>soc-medium</code> - Moderate strictness (60% confidence)</li> <li><code>soc-hard</code> - Maximum strictness (75% confidence)</li> </ul> <p>Confidence Threshold</p> <ul> <li>Slider: 0.0 to 1.0</li> <li>Default: 0.50</li> <li>Controls when predictions are marked \"uncertain\"</li> </ul> <p>Max Classes</p> <ul> <li>Number of top predictions to display</li> <li>Range: 1-7</li> <li>Useful for exploring runner-up classifications</li> </ul>"},{"location":"ui-guide/#llm-configuration","title":"LLM Configuration","text":"<p>Enable LLM Second Opinion</p> <ul> <li>Toggle AI-assisted classification</li> <li>Engages automatically for uncertain cases</li> <li>Provides alternative perspective with rationale</li> </ul> <p>Debug Mode</p> <ul> <li>Shows detailed LLM prompts and responses</li> <li>Useful for troubleshooting</li> <li>Performance analysis</li> </ul>"},{"location":"ui-guide/#visualization-options","title":"Visualization Options","text":"<p>Advanced Visualizations</p> <ul> <li>Enable enhanced charts and graphs</li> <li>Risk radar charts</li> <li>Confidence distributions</li> <li>MITRE technique heatmaps</li> </ul>"},{"location":"ui-guide/#analysis-tabs-single-incident","title":"\ud83d\udcca Analysis Tabs (Single Incident)","text":""},{"location":"ui-guide/#tab-1-analysis","title":"Tab 1: \ud83c\udfaf Analysis","text":"<p>Core classification results with key metrics.</p> <p> Main analysis results with confidence metrics</p> <p>Displays:</p> <ul> <li>Final classification label</li> <li>Confidence score with gauge visualization</li> <li>Uncertainty level indicator</li> <li>Top-N probability distribution</li> <li>Class probability pie chart</li> </ul>"},{"location":"ui-guide/#tab-2-visualizations","title":"Tab 2: \ud83d\udcca Visualizations","text":"<p>Interactive charts and visual analytics.</p> <p> Visual analytics dashboard</p> <p>Charts:</p> <ul> <li>Confidence gauge (speedometer-style)</li> <li>Probability distribution (pie chart)</li> <li>Risk radar (multi-dimensional assessment)</li> <li>Text complexity metrics</li> </ul>"},{"location":"ui-guide/#tab-3-threat-intel","title":"Tab 3: \ud83d\udd75\ufe0f Threat Intel","text":"<p>Comprehensive threat intelligence analysis.</p> <p> Threat intelligence panel with IOC extraction</p> <p>Features:</p> <ul> <li>MITRE ATT&amp;CK technique mapping</li> <li>IOC extraction (IPs, URLs, emails)</li> <li>Attack sophistication scoring</li> <li>Threat landscape context</li> <li>Related campaigns/TTPs</li> </ul>"},{"location":"ui-guide/#tab-4-soc-playbook","title":"Tab 4: \ud83d\udccb SOC Playbook","text":"<p>Context-aware incident response recommendations.</p> <p> SOC playbook with actionable recommendations</p> <p>Provides:</p> <ul> <li>Incident priority (P1-P5)</li> <li>Response timeline</li> <li>Step-by-step actions</li> <li>Context-specific guidance</li> <li>Escalation paths</li> </ul>"},{"location":"ui-guide/#tab-5-technical-details","title":"Tab 5: \ud83d\udd27 Technical Details","text":"<p>Raw data and technical information.</p> <p> Technical debugging and raw JSON output</p> <p>Includes:</p> <ul> <li>Full JSON response</li> <li>Text complexity analysis</li> <li>Model metadata</li> <li>Debug information</li> <li>LLM prompts/responses (if enabled)</li> </ul>"},{"location":"ui-guide/#bulk-analysis-features","title":"\ud83d\udcc8 Bulk Analysis Features","text":""},{"location":"ui-guide/#upload-processing","title":"Upload &amp; Processing","text":"<p>Supported Formats:</p> <p>CSV:</p> <pre><code>description\n\"User reported suspicious email with attachment\"\n\"Multiple failed login attempts from Asia\"\n\"Unusual outbound traffic to 192.168.1.100\"\n</code></pre> <p>TXT (one incident per line):</p> <pre><code>User reported suspicious email with attachment\nMultiple failed login attempts from Asia\nUnusual outbound traffic to 192.168.1.100\n</code></pre> <p>Processing:</p> <ul> <li>Real-time progress bar</li> <li>Estimated time remaining</li> <li>Incident counter</li> <li>Error handling with retry logic</li> </ul> <p> File upload and processing interface</p>"},{"location":"ui-guide/#results-dashboard","title":"Results Dashboard","text":"<p>After processing completes, view comprehensive analytics:</p> <p> Aggregate results with filtering and export</p> <p>Metrics:</p> <ul> <li>Total incidents processed</li> <li>Label distribution</li> <li>Average confidence</li> <li>LLM-resolved count (when second opinion used)</li> <li>Uncertain case count</li> </ul> <p>Interactive Table:</p> <ul> <li>Sortable columns</li> <li>Filterable by label, confidence, uncertainty</li> <li>Expandable rows for full incident text</li> <li>Color-coded by risk level</li> </ul>"},{"location":"ui-guide/#advanced-analytics","title":"Advanced Analytics","text":"<p>Access four analytics dashboards:</p> <p>\ud83d\udcc8 Overview</p> <ul> <li>Label distribution pie chart</li> <li>Confidence histogram</li> <li>Timeline analysis</li> <li>MITRE technique frequency</li> </ul> <p>\ud83c\udfaf Confidence Analysis</p> <ul> <li>Confidence vs label scatter plot</li> <li>Uncertainty distribution</li> <li>High/low confidence breakdown</li> <li>Threshold impact analysis</li> </ul> <p>\u26a1 Performance</p> <ul> <li>Processing speed metrics</li> <li>Model inference time</li> <li>LLM overhead analysis</li> <li>Resource utilization</li> </ul> <p>\ud83d\udd2c Deep Dive</p> <ul> <li>Text complexity analysis</li> <li>N-gram frequency</li> <li>IOC extraction summary</li> <li>Correlation matrices</li> </ul> <p> Advanced analytics with multiple visualization panels</p>"},{"location":"ui-guide/#export-options","title":"Export Options","text":"<p>Download results in multiple formats:</p> <p>CSV Export:</p> <pre><code>description,label,confidence,display_label,llm_override,mitre_techniques\n\"...\",phishing,0.87,phishing,No,\"T1566.001,T1204.002\"\n</code></pre> <p>JSON Export:</p> <pre><code>{\n  \"description\": \"...\",\n  \"label\": \"phishing\",\n  \"confidence\": 0.87,\n  \"display_label\": \"phishing\",\n  \"llm_second_opinion\": {...},\n  \"probabilities\": {...},\n  \"mitre_techniques\": [\"T1566.001\"]\n}\n</code></pre> <p>Threat Intelligence Brief:</p> <ul> <li>Executive summary (Markdown/PDF)</li> <li>MITRE coverage report</li> <li>Critical incidents highlight</li> <li>Strategic recommendations</li> </ul>"},{"location":"ui-guide/#experimental-lab-tools","title":"\ud83e\uddea Experimental Lab Tools","text":""},{"location":"ui-guide/#text-similarity-analysis","title":"Text Similarity Analysis","text":"<p>Compare incidents and find similar patterns.</p> <p> Text similarity clustering visualization</p> <p>Methods:</p> <ul> <li>TF-IDF cosine similarity</li> <li>Semantic embeddings</li> <li>Clustering (K-means, DBSCAN)</li> <li>Similarity heatmaps</li> </ul>"},{"location":"ui-guide/#model-comparison","title":"Model Comparison","text":"<p>Benchmark different classifiers.</p> <p>Models:</p> <ul> <li>Logistic Regression (baseline)</li> <li>Random Forest</li> <li>Linear SVM</li> <li>Ensemble methods</li> </ul> <p>Metrics:</p> <ul> <li>Accuracy comparison</li> <li>Confusion matrices</li> <li>Per-class performance</li> <li>Feature importance</li> </ul>"},{"location":"ui-guide/#synthetic-data-generation","title":"Synthetic Data Generation","text":"<p>Create test datasets on-demand.</p> <p>Parameters:</p> <ul> <li>Incident type</li> <li>Complexity level</li> <li>Batch size</li> <li>Include IOCs/MITRE/timestamps</li> <li>Export format</li> </ul>"},{"location":"ui-guide/#configuration","title":"\u2699\ufe0f Configuration","text":""},{"location":"ui-guide/#environment-variables","title":"Environment Variables","text":"<p>The UI respects the same environment variables as the CLI:</p> <pre><code># LLM Configuration\nexport TRIAGE_LLM_MODEL=/path/to/llama-2-7b-chat.Q5_K_S.gguf\nexport TRIAGE_LLM_DEBUG=1\nexport NLP_TRIAGE_LLM_TEMPERATURE=0.2\nexport NLP_TRIAGE_LLM_MAX_TOKENS=512\n\n# Model Paths\nexport TRIAGE_LLM_CTX=4096\n</code></pre> <p>See Configuration Guide for complete settings.</p>"},{"location":"ui-guide/#custom-styling","title":"Custom Styling","text":"<p>Modify <code>ui_premium.py</code> to customize the interface:</p> <p>Color Schemes:</p> <pre><code># Located at top of ui_premium.py\n.metric-card {\n    background: linear-gradient(135deg, #667eea 0%, #764ba2 100%);\n    ...\n}\n</code></pre> <p>Chart Types:</p> <ul> <li>Plotly graph configurations</li> <li>Streamlit theme settings</li> <li>Layout adjustments</li> </ul>"},{"location":"ui-guide/#tips-best-practices","title":"\ud83d\udca1 Tips &amp; Best Practices","text":""},{"location":"ui-guide/#performance-optimization","title":"Performance Optimization","text":"<p>\u2705 Use baseline first - Test without LLM for 10-20x faster processing \u2705 Batch processing - Process multiple incidents in bulk mode \u2705 Adjust max classes - Limit to 3-5 for faster rendering \u2705 Cache results - Export and reload rather than re-analyzing</p>"},{"location":"ui-guide/#accuracy-improvements","title":"Accuracy Improvements","text":"<p>\u2705 Tune thresholds - Lower (0.3-0.4) for coverage, higher (0.6-0.7) for precision \u2705 Use difficulty modes - <code>soc-hard</code> for critical infrastructure \u2705 Enable LLM selectively - Only for uncertain/high-stakes cases \u2705 Review uncertain - Manual analysis for low-confidence predictions</p>"},{"location":"ui-guide/#workflow-recommendations","title":"Workflow Recommendations","text":"<p>\u2705 Single \u2192 Bulk - Test single incidents first, then scale to bulk \u2705 Export everything - Save results for audit trails \u2705 Use playbooks - Follow SOC recommendations systematically \u2705 Monitor metrics - Track confidence trends over time</p>"},{"location":"ui-guide/#what-to-avoid","title":"What to Avoid","text":"<p>\u274c Don't trust blindly - Always review uncertain predictions \u274c Don't over-rely on LLM - It's decision support, not ground truth \u274c Don't ignore confidence - Low scores = unreliable classifications \u274c Don't skip validation - Verify results against ground truth when available</p>"},{"location":"ui-guide/#troubleshooting","title":"\ud83d\udd27 Troubleshooting","text":""},{"location":"ui-guide/#common-issues","title":"Common Issues","text":"<p>\"Model files not found\"</p> <pre><code># Trigger automatic download\npytest tests/test_model.py -v\n</code></pre> <p>Slow LLM processing</p> <ul> <li>Use quantized models (Q5_K_S recommended)</li> <li>Enable GPU acceleration via llama-cpp-python</li> <li>Reduce context window: <code>export TRIAGE_LLM_CTX=2048</code></li> <li>Lower temperature for faster generation</li> </ul> <p>CSV upload fails</p> <ul> <li>Ensure <code>description</code> column exists</li> <li>Check UTF-8 encoding</li> <li>Remove empty rows</li> <li>Verify proper CSV delimiter (comma)</li> </ul> <p>UI crashes or freezes</p> <ul> <li>Check terminal output for errors</li> <li>Verify sufficient RAM (8GB+ recommended)</li> <li>Close other applications</li> <li>Reduce LLM context window if OOM</li> </ul> <p>Blank visualizations</p> <ul> <li>Enable \"Advanced Visualizations\" in sidebar</li> <li>Check browser console for JavaScript errors</li> <li>Refresh page</li> <li>Try different browser (Chrome/Firefox recommended)</li> </ul>"},{"location":"ui-guide/#debug-mode","title":"Debug Mode","text":"<p>Enable detailed logging:</p> <pre><code>export TRIAGE_LLM_DEBUG=1\nstreamlit run ui_premium.py\n</code></pre> <p>Check terminal output for:</p> <ul> <li>LLM prompts and responses</li> <li>Model loading status</li> <li>Processing errors</li> <li>Performance metrics</li> </ul>"},{"location":"ui-guide/#related-documentation","title":"\ud83d\udd17 Related Documentation","text":"<ul> <li>CLI Usage - Command-line interface guide</li> <li>LLM Integration - Setting up local LLM models</li> <li>Configuration - Environment variables and settings</li> <li>API Reference - Programmatic access</li> <li>Architecture - System design and components</li> </ul> <p>Need help? Open an issue on GitHub or check the FAQ.</p>"}]}